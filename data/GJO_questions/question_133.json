{"question_id": 133, "title": "Will Google's AlphaGo beat world champion Lee Sedol in the five-game Go match planned for March 2016?", "correct_answer": "Yes", "crowd_forecast": 0.98, "preds": [[14145, "2016-03-12T14:08:04Z", 1.0, "I just believe."], [22108, "2016-03-12T14:00:35Z", 1.0, "Post hoc."], [689, "2016-03-12T12:47:27Z", 1.0, "Comment deleted on May 10, 2016 11:10PM UTC"], [1474, "2016-03-12T08:55:05Z", 0.95, "100"], [855, "2016-03-12T04:40:33Z", 1.0, "Given its standing two games up to 0.  I would find it very surprising if Alpha Go did not win at least one game.  Interesting article in Wired today.  http://www.wired.com/2016/03/sadness-beauty-watching-googles-ai-play-go/\nParticularly liked the comments by Fan Hui that he has moved up in the ranking after playing Alpha Go for the last 6 months."], [102, "2016-03-12T04:00:03Z", 0.87, "https://larswericson.wordpress.com/2016/03/12/gitrep-11mar16pm/"], [22079, "2016-03-11T23:52:28Z", 1.0, "Inevitable at this point, certainly?"], [2593, "2016-03-11T21:59:38Z", 0.95, "One of the ultimate strengths of AlphaGo is is the play in the middle of the board. This is a very difficult part of the board for human players as the complexity is very difficult to plan for a hundred moves ahead. The computer uses that advantage right from the beginning. The 2 or 3 moves that  surprised the human players eventually tied  into a strong middle position but only after dozens of moves were made. The professionals were asking themselves \"why there?\" In the last game Lee spent a good 25 minutes trying to figure out a move by AlphaGo that was not expected. \n Not only will Alphago increase the ability of computers to do complex tasks but will also help the Go community develop new strategies. Adding new moves to a 2,500 year old game is amazing. "], [51, "2016-03-11T21:15:04Z", 1.0, "Affirming naturally.  Now this is Google showing off their new impressive toy.  Good for them by the way."], [21164, "2016-03-11T21:09:17Z", 0.95, "Based on the current track record, and that fact that Go requires a player to gauge an opponents body language to reach a truly comprehensive understanding of their mindset. Lee Sedol lacks the ability to gauge the computers body language as he would a human opponent, thus he is at a disadvantage"], [691, "2016-03-11T18:59:07Z", 0.99, "Grim days for the meat fans:  A machine can figure you out faster than you can figure out the machine.  So far, of course, only or mostly in fairly tightly constrained contexts, but get used to it."], [17820, "2016-03-11T18:02:18Z", 1.0, "too good so far."], [55, "2016-03-11T16:42:09Z", 1.0, "Won a second game!"], [19807, "2016-03-11T16:20:06Z", 0.99, "Resistance is futile."], [176, "2016-03-11T15:36:21Z", 1.0, "Holy schnikes! "], [21924, "2016-03-11T13:22:39Z", 1.0, "Sedol has less than .5% chance of winning. Rounding to nearest %."], [22031, "2016-03-11T11:54:15Z", 0.95, "if it knows every possible move and counter"], [22025, "2016-03-11T07:29:26Z", 0.85, "The human has lost the first game and the European champion lost all 5. Nothing so far has shown that intuition and feel will best computation"], [1106, "2016-03-11T04:46:48Z", 1.0, "human cannot beat computer AI in a game rely on probability alone, just like no human can calculate faster than a computer no matter how good he is. it is not about how powerful over the opponent, it is about how little mistakes you make in a given situation, computer like alphago basically has close to zero faults for every moves because it can calculate all the probablity of winning each step without error. a human can not beat alphago by following a given set of rules which the algorithm has already trained itself to perfection. He can only win by smashing the computer during the game, alphago can't foresee this happen."], [3320, "2016-03-11T03:52:13Z", 0.97, "I've done a complete reversal.  Not long before the first game, I put AlphaGo's chances at about 10% (I think).  After the first game, I moved up only to 35%, thinking that Lee Sedol had been over-confident and had tried some doubtful moves to test the system.  After two wins for AlphaGo, it seems to me highly unlikely that Lee can win three straight.   I was struck by a comment by one of the programmers on the AlphaGo design team, made during the English-language commentary.  The American pro (Michael Redmond, 9p) had remarked that one of AlphaGo's moves were what strong Go players would call \"slow.\"  A slow move is not a bad move, just one that is less than optimal, usually because it allows one's opponent to regain the initiative in exchange for what appears at the time to be only a modest gain.  The programmer said, in effect, this isn't a bug -- it's a feature.  AlphaGo doesn't care about the size of a win.  Given a choice between two moves -- one that the program's database suggests will offer a 75% probability of a 20-point win and another with an 80% probability of  a 2-point win, AlphaGo will choose the second move.  Few human players, even very good players, will do this.  It's commonplace for Go players to say (often about their own losses), \"I was greedy.\"  I've lost a lot of games due to this kind of overplay.  \"Greed\" aside, it often seems reasonable at the time.  Most of us have no way of knowing the probabilities of a win or loss until late in a game, so naturally we tend to push hard.  (Or sometimes we're intimidated by a strong player and make \"slow\" moves out of fear.)  AlphaGo knows neither greed nor fear and has enough games in its database to make an educated guess on the probability that a move will lead to a win, even if the win is only by 1-2 points and the probability only 51%.  So I'd agree with a comment by GJDrew that Lee Sedol may lack AlphaGo's \"objectivity,\" but I'd disagree with the implication that its due to his lack of study or anything else.  But my present guess is that it'll be almost impossible for Lee to win three straight against a program that represents objectivity quantified."], [1529, "2016-03-11T03:36:37Z", 1.0, "Not changing my %, but simply want to add a comment in respect of Sedol...."], [2, "2016-03-11T03:13:19Z", 0.9, "Notice that the next match is not until the 12th.  So Sedol has a few days to recoup.  "], [18969, "2016-03-11T02:20:53Z", 0.97, "Down 0-2..."], [14137, "2016-03-11T01:23:26Z", 0.99, "Revising up my forecast again (from 98%) following the second match win to AlphaGo. I began at 75% and revised to 98 after the first match."], [22009, "2016-03-11T01:02:54Z", 0.9, "AlphaGo will win four and tie one with Lee Sedol. "], [2586, "2016-03-10T22:36:43Z", 0.88, "The king is dead. Long live the king."], [19306, "2016-03-10T21:15:07Z", 0.78, "Alphago is good and only need one more game"], [1629, "2016-03-10T20:27:10Z", 0.93, "Lee Sedol loss his first game to AlphaGo http://www.dailymail.co.uk/sciencetech/article-3483569/It-s-1-0-AlphaGo-Google-s-DeepMind-computer-BEATS-human-champion-Lee-Sedol-battle.html."], [20562, "2016-03-10T20:23:38Z", 1.0, "Taking what I previously rounded down to 99% and rounding up to 100%"], [83, "2016-03-10T19:56:40Z", 1.0, "Match 2 comments:\nLee Sedol - never a point were I felt I was leading\nAlphGo - confident of victory at the mid point\nProfessional Commentators - At mid point, were unable to determine who was winning\nhttp://www.theverge.com/2016/3/10/11191184/lee-sedol-alphago-go-deepmind-google-match-2-result"], [20588, "2016-03-10T19:55:59Z", 0.98, "Updating from 85 to 98. Sorry, humans."], [651, "2016-03-10T19:29:41Z", 0.9, "Two victories by AlphaGo suggest that initial pessimistic expectations were in need of revision."], [767, "2016-03-10T19:22:05Z", 1.0, "After watching game one, I increased my forecast from 35 to 70.  After watching game two, I'm going for 100.  Although I was wrong, I've really enjoyed forecasting this question. Truly historic, not to mention absolutely exciting to watch.  "], [60, "2016-03-10T19:01:53Z", 1.0, "Raising form 98 to 100."], [13361, "2016-03-10T18:36:12Z", 1.0, "Now that it's 2-0, AlphaGo's win looks very likely."], [17875, "2016-03-10T17:52:56Z", 1.0, "I started at 75% and was wrong about Sedol's ability to anticipate AlphaGo's innovative and unexpected play.  So, back up to 100%  : ) "], [16742, "2016-03-10T17:16:56Z", 0.99, "2/5"], [20549, "2016-03-10T16:54:30Z", 0.99, "Hate to jump on the bandwagon but this looks like it's cinched. Unless Lee pulls out a victory in game 3, I don't see this forecast changing."], [21924, "2016-03-10T16:15:42Z", 0.99, "Sedol will have to win all three of the subsequent games.  Pretty much impossible task given how things look."], [21958, "2016-03-10T16:05:18Z", 0.85, "The approach taken by the developers at Google is a very good one for the game of Go.  The combination of raw compute power (to examine outcomes from initial guesses from learned strategies) and reinforcement learning is going to lead ultimately to human defeat.  My initial guess is clearly on the strong side of yes, but at the moment I don't have a good feel between the relative strengths between the player in the previous victory and Lee.  It's not clear to me how the ranking differences accurately measure the (absolute) differences in skill.  My suspicion is that the differences in rankings exaggerate the absolute differences and that the players are closer to one another in compute/skill than indicated by rank."], [19476, "2016-03-10T16:05:11Z", 0.96, "AlphaGo won the second round of the 5 game match against Lee Sedol. "], [4288, "2016-03-10T15:58:55Z", 0.86, "Based on second game result. Economist provides a nice summary of the two algorithms being used by AlphaGo. http://www.economist.com/news/science-and-technology/21694540-win-or-lose-best-five-battle-contest-another-milestone "], [3363, "2016-03-10T15:31:22Z", 0.91, "Still below 100 just in case Lee Sedol is secretly fooling us all."], [19807, "2016-03-10T15:29:26Z", 0.95, "Ooops... AlphaGo is 2-0... "], [2, "2016-03-10T15:00:36Z", 0.93, "Moving up a bit more after reading Lee's own assessment:"], [2, "2016-03-10T14:56:22Z", 0.9, "No change.  Just more postmorteming...  another factoid I missed that I wish I knew earlier:"], [20044, "2016-03-10T14:52:19Z", 0.99, "Even ignoring my previous reasoning, and assuming AlphaGo and Lee Sedol are evenly matched with each having a 50% chance of winning a game (although this now seems unlikely, considering AlphaGo played an essentially errorless game in round 2), Lee Sedol would have just a 12.5% chance of winning the remaining 3 games. "], [14327, "2016-03-10T14:50:38Z", 1.0, "As others have noted - I strongly doubt that Sedol will win all 3 of the next games given \n1. His loss of both of the previous two \n2. His statements after the match, saying he felt like AlphaGo was in the lead the whole time "], [5001, "2016-03-10T14:15:13Z", 0.97, "AlphaGo played more creatively! It's as if the traditional human/computer roles were reversed. "], [19218, "2016-03-10T13:32:26Z", 0.97, "My old prediction was plainly silly!"], [16026, "2016-03-10T13:32:10Z", 0.98, "AlphaGo won against lee in both going first and later, and mental pressure for lee is very high.\n"], [15477, "2016-03-10T13:26:49Z", 0.95, "Now up 2-0.  Very slim chance Lee can pull this off."], [19106, "2016-03-10T13:16:04Z", 0.97, "That game felt like it could have gone Lee's way. I'm not sure whether that's a sign that it was actually close, or that traditional human evaluations of game board value are off, and Alphago was \"winning\" the entire time."], [110, "2016-03-10T13:10:19Z", 1.0, "Throwing in the towel."], [21800, "2016-03-10T13:04:20Z", 1.0, "Coming back from 2-0 down against an AI opponent should be next to impossible."], [915, "2016-03-10T12:34:38Z", 1.0, "Google = Skynet."], [689, "2016-03-10T12:15:16Z", 0.89, "Comment deleted on May 10, 2016 11:09PM UTC"], [51, "2016-03-10T11:24:07Z", 1.0, "AI just won second game.  Only needs to win one more to win three of five.  "], [1646, "2016-03-10T11:22:04Z", 1.0, "crushed..."], [17819, "2016-03-10T10:38:13Z", 0.9, "If alpha go wins only one more game it wins the five-game match. Judging by the way it played today, I see it as very unlikely that it will lose tomorrow's game."], [19432, "2016-03-10T10:23:08Z", 0.7, "as per comments and articles looks like deep mind is slightly better. still needs 1/3 matches to win the series, would give it a slightly higher chance than just 2/3rds probability"], [19449, "2016-03-10T09:04:47Z", 0.92, "Looking less and less likely"], [68, "2016-03-10T08:33:58Z", 1.0, "AlphaGo wins 2-0!"], [1993, "2016-03-10T08:33:52Z", 1.0, "I watched most of the match this time. Lee Sedol and AlphaGo seemed evenly matched most of the time. But Lee missed potential for points in the center of the board, which the commentator also missed until the opportunity had passed. I wonder if the fact that humans are accustomed to analyzing the board visually is a disadvantage when playing against a computer. Result: Lee resigned when they were both in overtime. "], [11080, "2016-03-10T08:28:01Z", 1.0, "AlphaGo has just won the second game. This looks like it's done - don't see Lee Sedol coming back from a 2-0 hole."], [2, "2016-03-10T08:11:12Z", 0.75, "Looks like AlphaGo is ahead in the 2nd game too, moving up."], [60, "2016-03-10T07:59:23Z", 0.98, "Upping from 91 to 98."], [21939, "2016-03-10T07:53:56Z", 0.99, "Before the first match i made a prediction that the score will be 5:0 or 4:1,but i am not sure who would win the match. My opinion was it must be a overwhelming outcome,whether for Lee or AlphaGO. After the first match, I could say its a 99 percent winning rate and the score will be 5:0 or 4:1\u00e3\u20ac\u201a"], [2, "2016-03-10T06:25:16Z", 0.58, "No change, but one thing the expert on the stream said was interesting.  When describing the prior efforts at a Go robot, he said that the prior efforts had weaknesses that made them amateur, but if they were allowed to play their own game, they were around 5-dan.  Which is actually much better than I thought they were.  "], [102, "2016-03-10T04:59:43Z", 1.0, "http://www.nytimes.com/2016/03/10/world/asia/google-alphago-lee-se-dol.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=photo-spot-region&region=top-news&WT.nav=top-news&_r=0"], [14327, "2016-03-10T04:15:10Z", 0.95, "Lee himself said the final score will be either 5-0 or 4-1. "], [2, "2016-03-10T04:13:40Z", 0.58, "Here's a less breathless article, plus @morrelldaniels that Lee was actually 3-3.5 pts ahead, but lost due to the handicap for going 2nd.  Just going to moderate slightly."], [1993, "2016-03-10T03:26:11Z", 0.5, "Lee made a mistake early on. AlphaGo also made mistakes and is clearly exploitable. I'm sure Lee learned a lot in the first game. I give him a 50/50 chance until I see the second game."], [498, "2016-03-10T02:07:03Z", 0.2, "Mr. Lee said he knew he had lost the match after AlphaGo made a move so unexpected and unconventional that he thought \u201cit was impossible to make such a move.\u201d\nhttp://www.nytimes.com/2016/03/10/world/asia/google-alphago-lee-se-dol.html?_r=0"], [14137, "2016-03-10T01:30:22Z", 0.98, "Having won the first game makes it all but certain AlphaGo will win the round. AlphaGo improves every game, while a human player is more likely to be derailed by an unexpected (to them) loss."], [83, "2016-03-10T01:06:23Z", 0.98, "Lee Sedol must win 3 of 4 matches."], [3320, "2016-03-10T00:55:52Z", 0.35, "Well, a day or so ago I was giving AlphaGo only a 10% chance.  The program is obviously much stronger than I thought possible.  Lee Sedol made some doubtful moves (or so players competent to have an informed opinion write) as did AlphaGo.  The game was close.  Redmond thought that Lee won \"on the board,\" meaning that AlphaGo won because of the _komi_ (handicap to compensate for Black's first move).  I think Lee will play better, and I doubt that AlphaGo will \"learn\" that much overnight since it's database already must includes many thousands of games.  The big factor may be fatigue.  This is a pretty stressful contest for a human, and AlphaGo won't get tired. ( I'm what the commentators call a mid-kyu level player.   If I played basketball as well as I play Go, you'd be glad to have me on your team for a pickup game at the Y, and maybe I'd be a starter for a small-town high school.)  Anyway, I'm still betting on Lee Sedol but with less confidence."], [21924, "2016-03-10T00:49:57Z", 0.87, "How likely is it for Lee to not make any more mistakes?  Pretty unlikely I think, especially now that the pressure is on.\nBefore the game, Lee predicted it would be 5-0 or 4-1, and he will fight for the 5-0."], [19306, "2016-03-09T21:22:44Z", 0.69, "First game was won by Alphago, wich seems stronger than I have guessed => Updating my forecast"], [4288, "2016-03-09T20:12:17Z", 0.81, "Despite Lee Sedol now observing how AlphaGo plays, this will be of relative help to Sedol. This is because AlphaGo is dynamical in its learning; meaning the opponent that Sedol will play will be be a different opponent each and every time. As the saying goes, 'you can never step into the same river twice'  "], [17875, "2016-03-09T19:38:11Z", 0.0, "Alphago won the first game - not unexpected.  The game was beautiful. I was so happy to see AlphaGo play aggressive and against convention in many ways.  I don't know Go so I had to watch through great commentary:  https://www.youtube.com/watch?v=6ZugVil2v4w"], [12413, "2016-03-09T19:10:28Z", 0.75, "Increasing my prediction after first match"], [17875, "2016-03-09T19:09:15Z", 0.0, ": )"], [11885, "2016-03-09T19:02:59Z", 1.0, "Wondering how I could have forecasted 0% just y'day. My Snowie backgammon software kills me since 10Y+. & wasn't it Brad DeLong who just recently argued that we may have reached Peak-human\". I wonder when bots will make a killing in this nice good-judgement competitions."], [1500, "2016-03-09T18:46:54Z", 0.75, "Upping my forecast since AlphaGo won the first game."], [19807, "2016-03-09T18:20:42Z", 0.25, "AlphaGo won Match 1. Not going to be easy."], [3474, "2016-03-09T18:08:05Z", 0.5, "Hedging bets."], [2, "2016-03-09T18:05:26Z", 0.64, "http://www.nytimes.com/2016/03/10/world/asia/google-alphago-lee-se-dol.html?_r=0"], [19432, "2016-03-09T18:02:54Z", 0.6, "Previous rationale plus developments of today with alpha go beating lee seedol in the first game "], [909, "2016-03-09T17:40:37Z", 0.99, "The singularity is nigh, AlphaGo won.  "], [110, "2016-03-09T17:37:57Z", 0.25, "http://www.businessinsider.com/heres-how-much-computing-power-google-deepmind-needed-to-beat-lee-sedol-2016-3"], [1646, "2016-03-09T16:48:40Z", 0.9, "watching the game live made me want to be in a live go prediction tournament. Would such a thing be technically possible? Observers of the game predicting AlphaGo\u00b4s and Lee Sedol\u00b4s next movement, getting running Brier\u00b4s scores for it, and identifying the best predictors with possibly a chance to go against AlphaGo themselves... "], [1529, "2016-03-09T15:31:53Z", 0.93, "AlphaGo was able to slightly edge out a 9 DAN-LEVEL player. The complexity of the endgame was the deciding difference. Notably, AphaGo was willing and able to play aggressively at this top level. Probably most people did not expect this level of capability. Psychologically, this is a big weight that human player has to carry. For alpha, it's just in a day's work. It looks like AlphaGo has an edge in the endgame due to its massive computing power when there are less, but very critical, moves remaining."], [10783, "2016-03-09T15:08:21Z", 0.3, "I still think that Lee will win.  Perhaps I'm stubborn."], [2, "2016-03-09T15:06:39Z", 0.55, "Alpha Go won the first game.  Updating from 25% to 55%."], [180, "2016-03-09T15:01:46Z", 0.79, "AlphaGo up by one."], [20044, "2016-03-09T14:51:58Z", 0.96, "Upping my estimate slightly, from 95 - 96%. While I have long expected AlphaGo to win, I was surprised it was able to win the first game. It is important to note that AlphaGo will likely continue to improve as the matches occur, iterating through further games played against itself - only this time with the additional data gained from playing Lee Sedol himself. "], [13361, "2016-03-09T13:52:19Z", 0.85, "Well, I guess AlphaGo winning the first match against Lee Sedol answers the question about how good it has gotten over the last 6 months. I'll up my prediction that it will take the five-game match.\nhttp://www.kurzweilai.net/alphago-machine-learning-program-defeats-top-go-player-in-first-match"], [15477, "2016-03-09T13:08:57Z", 0.85, "Already won round 1"], [691, "2016-03-09T13:05:32Z", 0.76, "I expected the machine to lose the first game.  "], [19260, "2016-03-09T12:46:10Z", 1.0, "Well, I was very clearly wrong.  I didn't expect that playing itself (given the relative paucity of training data above the amateur level, and the limited scaling benefits of throwing more hardware at a Monte Carlo tree search) would genuinely let it train to high-professional levels.  Throwing all the way to 100% to balance out the long time I've had it  at 12%."], [110, "2016-03-09T12:28:29Z", 0.25, "http://www.businessinsider.com/google-deepmind-ai-alphago-defeats-human-lee-sedol-go-in-south-korea-2016-3"], [19106, "2016-03-09T11:57:52Z", 0.85, "All of my suspicions have been confirmed by the first game."], [3363, "2016-03-09T10:27:23Z", 0.83, "I, for one, welcome our new robot overlords."], [1468, "2016-03-09T10:22:21Z", 0.96, "http://www.wired.com/2016/03/googles-ai-wins-first-game-historic-match-go-champion/"], [21800, "2016-03-09T10:21:29Z", 0.99, "Alpha has won the first game. "], [15621, "2016-03-09T09:20:15Z", 0.95, "Alpha just won first game\nhttp://www.bbc.com/news/technology-35761246\n"], [19311, "2016-03-09T09:05:13Z", 0.75, "well, I didn't definitely expect this... Upping the chance sharply"], [20501, "2016-03-09T08:45:46Z", 0.96, "AlphaGo 1-0 warrants a strong update"], [20131, "2016-03-09T08:18:32Z", 0.8, "AlphaGo won the first game and so I upping the probability by 5%."], [19476, "2016-03-09T07:49:56Z", 0.73, "Upping my forecast in favor to AlphaGo after its win on the first match against Lee Sedol. \n"], [18914, "2016-03-09T07:44:22Z", 0.85, "Just to give you guys some information, after the first game, pros are still split on whether AlphaGo can win the series or not, and many are still confident in Lee Sedol."], [767, "2016-03-09T07:42:15Z", 0.7, "AlphaGo beat Lee SeDol on game one. Very close match but as I see it, this game was decisive. The computer will only improve in subsequent games. "], [5001, "2016-03-09T07:41:24Z", 0.65, "Wow"], [60, "2016-03-09T07:39:57Z", 0.91, "Upping from 14 to 91."], [20562, "2016-03-09T07:35:31Z", 0.99, "Gonna up my estimate from 87% and add a told ya so :D."], [4634, "2016-03-09T07:33:17Z", 1.0, "AlphaGo wins the first round"], [498, "2016-03-09T04:06:17Z", 0.1, "Game 1 Livestream\nhttps://www.youtube.com/watch?v=vFr3K2DORc8&internalcountrycode=JP"], [19936, "2016-03-09T02:30:05Z", 0.95, "Google are putting up 1M as a prize, have a big team on it, and their machine can scale with more hardware. Additionally, Sedol has few prior games to study, the previous with Fan did not exhibit the potential of the machine because it is defensive when it is ahead. It's likely to move fast and not give Sedol time to think. Kasparov in a similar situation became very nervous and Sedol admitted that it would feel like \"playing against himself.\" The real test will be in the later matches (March 10 Korean time) as the two players adapt to each other."], [767, "2016-03-09T01:01:08Z", 0.35, "At the press conference today, Lee Sedol was a lot less confident than he has previously shown to be, and said that, after learning more about the algorithm that Deepmind is using for AlphaGo, he no longer thinks that a 5-0 win is possible. http://www.koreaherald.com/view.php?ud=20160308000967"], [1107, "2016-03-09T00:25:34Z", 0.99, "The algorithm has the equivalent of 80 years of experience playing the game.\nhttp://www.businessinsider.com/googles-alphago-is-making-artifical-intelligence-history-2016-3 "], [767, "2016-03-08T19:12:27Z", 0.25, "We all know computers AI capability is exponentially increasing.  Despite the great team and resources behind ALPHAGO, I still think the human --this time around-- has the edge to beat it.  Much must have been learned and adjusted since ALPHAGO beat Fan Hui in October (the player ranked 537 in the world).  Fan Hui became one of the Deepmind advisors in programming ALPHAGO to teach it the game of Go.  "], [1529, "2016-03-08T16:52:20Z", 0.45, "EDIT (There can be no tie, so ignore this >>>>>(IFP requires AphaGo to \"beat\" Sedol, so a tie goes to Sedol for this IFP. Based on that aspect, lowering %)"], [12413, "2016-03-08T16:45:49Z", 0.65, "I have put my prediction back upwards, to 65% (originally 65%, then to 45% now 60%).  I feel I have underestimated the exponential learning capacity of the AI.  It is almost impossible to comprehend but the AI learning speed is astounding.  This is the advantage.  If you chart the learning speed of the AI, the AI can get exponentially better (the line curves upwards towards vertical) while if you took a toddler and taught him or her for a lifetime, the curve would be the opposite - starting almost vertically and then gradually pushing towards horizontal.   As humans we think too linear a fashion. "], [1106, "2016-03-08T15:38:23Z", 0.05, "According to other professional players, AlphaGo has not reach the top standard of professional player yet. it may win 1 or 2 games by chance"], [1218, "2016-03-08T15:25:18Z", 0.22, "From the American Go Journal - WATCH IT LIVE: the first Game will tell us all a lot!"], [4288, "2016-03-08T14:30:26Z", 0.69, "Based on Lee Sedol's comments. "], [21817, "2016-03-08T12:23:30Z", 0.35, "While AlphaGo reaches professional Go player level, it is not up to the level of top human players yet."], [21814, "2016-03-08T11:46:07Z", 0.4, "Comment deleted on May 11, 2020 09:00AM UTC"], [102, "2016-03-08T05:01:34Z", 0.65, "https://larswericson.wordpress.com/2016/03/08/gitrep-7mar16pm/"], [3320, "2016-03-07T20:23:10Z", 0.1, "This isn't very rational, but as a go player, I'm all too familiar with how a small difference in skill translates into consistent wins for the stronger player.  The difference in strength between Lee Sedol and the pro AlphaGo defeated is quite large.  There's no question that AlphaGo represents a huge breakthrough in AI, but a 9-dan pro can create complexities for which the games stored in the AlphaGo database offer no basis for optimizing next moves.  "], [21710, "2016-03-07T17:41:56Z", 0.35, "Complex game. If Google wins wil show a remarkable growth in AI."], [21710, "2016-03-07T17:40:06Z", 0.65, "Complex game. If Google wins, it will show the incredible growth on their AI."], [21649, "2016-03-07T16:35:29Z", 0.95, "The loss is worth less to the man, than a win is worth to Google here. AKA GOOG. "], [21687, "2016-03-07T16:08:04Z", 0.75, "They are leaders in AI (deep learning) and managed to create a champion winning chess AI."], [21653, "2016-03-07T15:28:55Z", 0.85, "Google wouldn't play this match if they weren't very confident they would win. They've had multiple months of training since last recorded ELO"], [21620, "2016-03-07T14:11:28Z", 0.78, "See Deep Blue vs. Gary Kasparov"], [14702, "2016-03-07T10:43:33Z", 0.3, "I think Lee Sedol will win this time.  In the future, the computer program will learn from its mistakes and beat him.  Alpha Go beat Fan Hui, who is ranked 2-dan.  Lee Sedol is ranked 9-dan and has been world champion for a decade.  He is a stronger player than Fan Hui.  Alpha Go beat Fan Hui 5 games to zero."], [94, "2016-03-06T23:24:56Z", 0.35, "Affirming"], [14327, "2016-03-06T21:21:03Z", 0.85, "http://www.tomshardware.com/news/google-alphago-vs-lee-se-dol,31142.html"], [21408, "2016-03-06T21:17:20Z", 0.79, "Seems to have experience with previous wins and time since then to develop strategy"], [21335, "2016-03-06T18:41:43Z", 0.89, "AlhaGo already has some feathers on it's cap. Moreover, it must have researched all the possibilities that can arise in Lee Sedol's mind. Be that as it may, the game offers Lee Sedol great deal of possibilities. Nevertheless the odds are stacked against him as he would only be able to go so far in tapping into the possibilities offered by Go. Hence, I wouldn't give Lee Sedol higher than 11% chance."], [102, "2016-03-06T04:01:33Z", 0.66, "https://larswericson.wordpress.com/2016/03/05/manual-category-assignment-work-in-progress/"], [20343, "2016-03-05T22:01:57Z", 0.6, "Need to understand what does it take to win a typical \"Go\" match and then assess the probability of a computer doing better than a human:"], [20882, "2016-03-05T21:19:02Z", 0.4, "I read Myungwan Kim's assessment on AlphaGo and am sure the Google team has been working hard to address the identified weaknesses.  Will 5 months be enough to for AlphaGo to beat Lee Se-dol?  I don't think so, however, I do expect AlphaGO to win 1 or 2 games."], [21128, "2016-03-05T17:59:38Z", 0.95, "I belive artificial intelligence has reached a level whereby cognitive abilities can mimic the human mind, but much faster.  As a result, I believe the probability of any human beating a computer is decreasing.  Google wouldn't play to lose."], [13361, "2016-03-05T17:37:01Z", 0.48, "OK, since the games take place next week (March 9-15), I'll update my forecast. It looks like the biggest question is how good has AlphaGo gotten in 6 months since October & no one except Google knows that answer & they aren't giving people any clues. The general Go community consensus was that it couldn't beat Lee in October. Now, it seems they are in the too close to call camp or giving one or the other a slight advantage. I will give Lee the slight advantage - only because AlphaGo is a black box at this point & I think it's impossible to predict how much progress it has made."], [1474, "2016-03-05T16:02:00Z", 0.96, "European Go champion was defeated 5-0 as outlined in the Nature paper published in Jan. Reinforcement learning is a genuinely useful set of mathematical methods,  which continues to show great levels of progress. With these set of games set to receive similar levels of attention as the Kasparov / Deep Blue series of chess games in 1996/97, Demis Hassabis has every incentive to ensure that AlphaGo will defeat Lee Sedol."], [15621, "2016-03-05T09:40:03Z", 0.61, "Just want to stay slightly on side of computer vs gjo predictions"], [18914, "2016-03-05T00:25:44Z", 0.85, "Being a go player, I REALLY REALLY hoped that Lee Sedol would win. One of the biggest reasons I started go was because bots could not defeat the top players in go. "], [3474, "2016-03-04T18:55:55Z", 0.15, "Computers are not good at fuzzy logic."], [21012, "2016-03-04T09:54:37Z", 0.75, "In October 2015, the distributed version of AlphaGo defeated the European Go champion, and since then Google team had several months to tweak and optimize the software. Moreover the machine will not suffer from pressure potentially put on by its opponent with aggressive moves."], [13377, "2016-03-04T08:33:16Z", 0.35, "https://larswericson.wordpress.com/"], [14327, "2016-03-04T04:36:32Z", 0.8, "Moving up based on @eron_gj 's / @aarongertler 's great link."], [17875, "2016-03-04T01:18:55Z", 0.0, ": )"], [436, "2016-03-04T00:45:51Z", 0.54, "Boosting my prediction based on this article, which taught me more about AlphaGo's ability to bring more processing power to bear in certain situations. I predicted earlier that Lee Sedol will think more carefully than Fan Hui did, given the world's attention on the match -- but AlphaGo may get a similar advantage if certain \"kid gloves\" exist to be taken off."], [21013, "2016-03-03T16:31:39Z", 0.7, "http://www.milesbrundage.com/blog-posts/alphago-and-ai-progress"], [21000, "2016-03-03T14:12:23Z", 0.85, "It's not a question of processing power its a question of developing suitable heuristics and now that teams are working ones that feedback into play (e.g. learn) its just a question of time before outstripping the best humans is achieved"], [19432, "2016-03-03T10:39:14Z", 0.58, "Alpha go has, as of now won 499/500 of it games with a computer software and all of its games with humans . Thus it has. Baseline win rate of 99.8%. Lee See dol has a 71.8% baseline win rate as per Wikipedia . Thus the balance is slightly tilts towards alpha go .  Given that the game has a big human component to it, I would be cautious to start with and say that the computer has a slightly higher chance of beating lee see dol than vice versa. "], [20501, "2016-03-03T10:34:07Z", 0.6, "Here's my take as a casual interested observer who tried to read the paper in Nature to understand how AlphaGo works and challenges faced."], [855, "2016-03-03T08:52:18Z", 0.55, "Frankly I think it could go either way, given Sedol's level and AlphaGo's continued ability to learn.  Slight advantage to the machine...."], [498, "2016-03-02T23:39:02Z", 0.1, "Per German poll cited by @dada: http://www.gjopen.com/comments/comments/155178 (-2)"], [20562, "2016-03-02T16:24:53Z", 0.87, "I am increasing my estimate to 87% after this comment alleviated some potential concerns."], [20892, "2016-03-02T14:49:48Z", 0.53, "HP"], [12413, "2016-03-02T14:33:27Z", 0.45, "I'm lowering my forecast to 45% from 65% this is a drastic change but after reading up on this it seems to me the weakness in Alphago right now is that it hasn't played versus many human players.  "], [18914, "2016-03-02T06:31:30Z", 0.5, "For people still skeptical about what I said in all my posts, and the difference between western and Asian players, here's a short article about a recent go tournament that gives a little idea of the go world: http://www.usgo.org/news/2016/03/korea-china-win-at-iemg-with-na-players-in-5th-place-li-scores-against-japan-pro/"], [20912, "2016-03-02T04:45:29Z", 0.95, "AlphaGo was stronger than a third dan last fall, and it has been constantly improving since then."], [1646, "2016-03-02T00:01:11Z", 0.32, "German Poll\nhttp://computer-go.org/pipermail/computer-go/2016-March/008741.html\nYou can join here\nhttp://www.go-baduk-weiqi.de/gewinnspiel-lee-sedol-gegen-alphago/"], [16025, "2016-03-01T20:21:47Z", 0.57, "C Over the course of time, even the smartest artificial intelligence devices have not been able to beat GO amateurs, however, Google\u2019s own AlphaGO has had a recent history of success, going 5-0 in a match against a European professional, and has beaten the vast majority of AI systems by a wide margin. AlphaGo has been programmed to \u201cmimic\u201d expert players and seems to be slightly favored to win the match against Lee Sedol. \nH Though an artificial system beating a human in GO has not happened as of yet, there is definite information to be discussed. Google has trained its AlphaGo system to memorize 30 million moves that were played by professional GO players, and it can now sensibly predict the next human move approximately 57 percent of the time. This was achieved through reinforcement learning, a form of learning that involves implementing new techniques and strategies through trial-and-error. \nA The most recent forecast for predicting AlphaGo\u2019s performance against world champion Lee Sedol was 55%, however the new forecast is 45%. There are several reasons for why AlphaGo may not actually have an edge in beating Lee Sedol. It appears as though Lee Sedol is a much stronger player than Fan Hui relative to AlphaGo. Elo ratings predict that Fan Hui would have a 25% chance of beating Lee in just one match. In addition, after his match against AlphaGo, Fan Hui noted that he wasn\u2019t able to play his conventional style against the computer, which may have actually contributed to his poor performance. In essence, AlphaGo\u2019s victory was impressive, however they may have a tougher time with Lee Sedol than anticipated. \nM Though no models have directly predicted AlphaGo\u2019s strength as a Go player, one may consider Fan Hui and Lee Sedol\u2019s Elo ratings in accordance to potential adjustments AlphaGo can make prior to the next match. Sedol\u2019s 2940 rating in comparison to Fan Hui\u2019s 2750 may not seem like that big of a difference, however, may professional\u2019s agree that Sedol is much stronger than a 2940 rating. AlphaGo can potentially play from a database of 100 million moves for its next match. \nP AlphaGo and Lee Sedol have not formally played their match, making it difficult to provide post-mortem analysis. For the time being, one can imagine that AlphaGo developers have been continuing to develop its intelligence through simulations against expert players. AlphaGo\u2019s continuing development should make for an interesting and exciting match against Sedol, with forecasts locked near a dead tie.\nS The most pressing questions that relate to this forecast are: How impressive was AlphaGo\u2019s win against Fan Hui? Will the match be set up to automatically favor AlphaGo? This could easily affect Sedol\u2019s playing style but may not actively reflect one of his better performances. Also, will AlphaGo\u2019s ever-expanding intelligence lead to a significant advantage over Sedol?\nK The key players in this situation have to be the Google developers. If AlphaGo play\u2019s how it played against Fan Hui (with a substantial amount of mistakes), it could have a tough match against Sedol. However, if Google developers can take the information from the match and implement it to make AlphaGo even stronger, it will make for a much better match. \nN Important policies that may swing the match in AlphaGo\u2019s favor are the rollout policy and rules on time limits. First, the match is likely to have a greater time limit for each player. This works in AlphaGo\u2019s favor because it gives the computers more time to make calculated and accurate moves. In addition, the rollout policy allows for AlphaGo developers to implement more training into their computers and use more power during the match. \nO Many articles have excluded the confirmed fact that AlphaGo lost 2 unofficial matches against FanHui. Is AlphaGo as good as people say it is? \nW Google developers have expressed confidence in their artificial intelligence systems and likely have some \u201ctricks up their sleeve\u201d for the match, which brings some unpredictability from AlphaGo\u2019s side. Everyone pretty much knows what to expect from Lee Sedol: high performance from the consensus number 1 go player for the last decade. Whether Google can significantly enhance its technology will be a driving factor in catching Sedol off guard and delivering a strong performance in March.\n"], [20833, "2016-03-01T05:04:15Z", 0.75, "Google is conscious of its own image. It is unlikely to roll this out until it can win."], [498, "2016-02-29T22:49:38Z", 0.12, " -1 on @Investmentitos' intimation that *real* Go pros are siding with Sedol, and adopting the heuristic that when you don't really know crap about an issue, it's OK to \"go with the pros\" (provided you can identify the *real* pros, and that you can adjust for whatever biases the real pros may have relative to your payout [which, as I've learned personally the hard way, is not the same as the outcome].)\nhttp://www.gjopen.com/comments/comments/153868"], [19150, "2016-02-29T22:18:42Z", 0.58, "It's hard to take an outside view on this question, because directly comparable situations don't exist. We can look at how computers have beaten world experts in chess and jeopardy, but GO is a level more complicated and tests the strength of artificial intelligence even further. In chess, it took years after the first chess-master tournament for the computer to beat the world expert. This is experience AlphaGo doesn't have.  "], [17875, "2016-02-29T14:10:19Z", 0.0, ": )"], [4972, "2016-02-29T10:44:53Z", 0.69, "Alphago beat the European champion 5-0. There is a good chance (69%) that it will beat the world champion by atleast 3/2"], [19936, "2016-02-29T07:06:13Z", 0.85, "Alpha Go seems to scale with bigger hardware and Google has plenty"], [436, "2016-02-29T02:43:53Z", 0.39, "My newest question is: To what extent can the AlphaGo team move to correct specific deficiencies in the program's play? (As opposed to merely giving it more material to learn from?) "], [6628, "2016-02-28T21:03:52Z", 0.95, "Go seems like something a computer would be great at. "], [11038, "2016-02-28T03:25:17Z", 0.65, "I am thinking 3-2 in the favor of AlphaGo.  Predicting the number of  number of games that it would take either to win would make for side wager"], [20698, "2016-02-27T20:08:00Z", 0.15, "Not yet: it will be too soon to beat the best."], [1468, "2016-02-27T10:29:54Z", 0.34, "Updating positively based on debate at: http://www.metaculus.com/questions/112/"], [20562, "2016-02-27T10:12:59Z", 0.82, "As per @balakirev's additional insights into Go rankings and play-styles (http://www.gjopen.com/comments/comments/148985), I am lowering my prediction by another 8%."], [498, "2016-02-27T07:42:41Z", 0.13, "AlphaGo creator remains confident\nhttp://koreajoongangdaily.joins.com/news/article/article.aspx?aid=3015421&cloc=rss|news|joongangdaily"], [20562, "2016-02-26T19:57:27Z", 0.9, "Found this article where Se-dol apparently states that he's been practicing against AlphaGo for an hour or two each day. "], [13601, "2016-02-26T16:46:09Z", 0.7, "Yes. This is due to belief that AlphaGo will learn more than Sedol in the timeframe up until their match. I think it will win 3-2"], [15166, "2016-02-26T13:13:39Z", 0.55, "Adjust and update forecasts when appropriate:"], [20129, "2016-02-26T09:22:21Z", 0.62, "AlophaGo beat the European Go Champion a few weeks ago 5-0. And it does not stop learning like the real Go masters. I believe in sheer crunching power over heuristics therefore I increase my forecast"], [498, "2016-02-26T05:12:09Z", 0.1, "Per @eron_gj's demonstration of the confidence of Google engineers, who clearly know far, far more about both AI and Go than I do. (+5)"], [19924, "2016-02-25T20:07:08Z", 0.99, "Recent research in machine learning makes it very difficult for humans to compete in the 'games' arena. Learning algorithms can see and deal with uncertainty a lot better than average humans, and I suspected that in the Go game, machines will beat top players from now on on a frequent basis.\nNature 529, http://www.nature.com/news/digital-intuition-1.19230\n"], [20588, "2016-02-25T18:04:02Z", 0.85, "The difference between Fan Hui proficiency and Lee Sedol's can't be all that much. If AlphaGo beat Fan 5-0, it'll likely beat Lee 3-2 or 4-1. Then again, there just isn't enough of a winning streak to be sure. This is only the second official match like this. "], [11586, "2016-02-25T18:01:47Z", 0.09, "Nope."], [20562, "2016-02-25T12:42:14Z", 1.0, "Actually, f* it. It would just be flat out way too weird for Google to challenge the top player if AlphaGo had tapered off at 3,100 elo."], [20562, "2016-02-25T12:27:25Z", 0.95, "IBM was a company. It made Deep Blue. IBM had a lot of very smart engineers, and it had a very smart PR department, and the very smart engineers had to convince the very smart PR department that Deep Blue could beat Kasparov. Deep Blue beat Kasparov (though I grant this was after an off-by-one year error). "], [498, "2016-02-25T07:22:05Z", 0.05, "I know nothing about AI, but this video provided me with some insight into how DeepMind approaches it. If I understand it correctly, it is responding to no more than a spatial configuration of reality. That is, it responds to no more than \"the pixels on the screen.\" It seeks to optimize some objective based on the current configuration of pixels. Well, that's the best I can do with my explanation so far. There's probably more to it. If there's any truth to my initial understanding of AI as implemented by DeepMind, I'm thinking that first, it is vulnerable to a novel configuration. How does it handle a configuration of reality it has never seen before? Second, it seems to lack any \"theory of mind.\" It responds to the what, not the why of the what. I'm not sure, but I'd think this lack of insight into the why of a move might make it susceptible to being tricked. Well, that's my 15 minute analysis of AI and my justification for my forecast.\nhttps://www.youtube.com/watch?v=rbsqaJwpu6A"], [17875, "2016-02-25T06:54:36Z", 0.0, " \u00af\\_(\u30c4)_/\u00af "], [1529, "2016-02-25T03:38:58Z", 0.55, "Not changing estimate, but for those interested in watching the past games between AlphaGo and Fan Hui.....\nhttp://www.usgo.org/news/2016/01/alphago-beats-pro-5-0-in-major-ai-advance/"], [18969, "2016-02-25T00:54:25Z", 0.28, "Slight reduction (-5%)  Just saw the video (https://www.youtube.com/watch?v=SUbqykXVx0A) which has a bit more insight into the scale of complexity of chess vs. Go.  It looks like the number of possible moves is about an order of magnitude higher in Go.  I think this give further credence to my principle notion that more time is needed for development in order to defeat a top human player - based on previous developments in chess.  Not only is the development time less than for chess, but the complexity is higher.  I think complexity will increase development time.  "], [20508, "2016-02-24T18:50:58Z", 0.85, "AlphaGo is probably machine learning and training all the relevant documented Go games in history while Lee sleeps."], [19106, "2016-02-24T17:52:56Z", 0.5, "I'm upping my estimate, after a great deal of thought and research in the course of writing an article on the upcoming match (actually mostly prompted by this GJ question though!). My prediction for AlphaGo's chances have gone from about a 20% chance to 50%."], [10921, "2016-02-24T15:18:26Z", 0.14, "Incresing my estimate given the confidence displayed by google that it is 50/50."], [19306, "2016-02-24T12:22:27Z", 0.21, "Following WJK questions, I m modifying my forecast to take into account the possibility that I maybe wrong  about my estimation of AlphaGo ELO. "], [20483, "2016-02-24T10:47:18Z", 0.43, "I believe the human mastery is yet to be matched by any algorithm. "], [19974, "2016-02-24T08:07:41Z", 0.75, "I read a number of commentaries on the AlphaGo vs Fan Hui match. The official results was very decisive, but they played a couple of unofficial games and Fan Hui won two of those. Hence, it seems that AlphaGo was not better by an order of magnitude. Other factors to consider: since the beginning of computer science, progress of AI was generally slower than expected, so betting against AI was historically a good bet. On the other hand, how likely is it that AlphaGo is vastly better than human players, but we didn't have a chance to see it yet? Also, how much better can AlphaGo get between October and March? Judging these factors, I move to from 50-50 to 75%..."], [17875, "2016-02-24T07:11:33Z", 0.0, ":)"], [19626, "2016-02-24T05:29:14Z", 0.75, "Read links based on articles about projected ELO ratings. Find these atgents quite convuncing, but believe the probability of Google substantially improving the algorithm by extensive training before the match to be quite good. Essentially being bullish on the Google staff given their considerable resource and how high profile this game has become."], [3320, "2016-02-23T20:31:33Z", 0.27, "I've gone back and forth on this one.  But Lee Sedol is so strong that he'll be able to capitalize on any sub-optimal move AlphaGo makes.  However, that may be true of AlphaGo as well.  But I doubt that AlphaGo can win three of five games against one of the world's best players."], [17875, "2016-02-23T05:05:24Z", 0.0, ": ) "], [19427, "2016-02-22T21:00:39Z", 0.65, "\"Park Chi-Moon, the vice-chairman of Korea\u2019s Go association, injected a note of caution for humanity. \u201cDeepMind said they believe AlphaGo has a 50% chance of winning \u2026 we believe they are in fact more confident,\u201d he said.\""], [20341, "2016-02-22T03:31:14Z", 0.75, "Even though there is no method for playing Go, the computer is capable of keeping a big numbers approach to the game. This gives the computer and edge beyond the random component of the game. Assuming the game is 50% chance and 50% ability the computer has a 100% in the ability side."], [14137, "2016-02-22T02:49:43Z", 0.75, "AlphaGo's first victory was against a far less skilled opponent than Lee Sedol, however the program is a continuously learning program. Given a 5 month period in which to improve, AlphaGo could emerge incredibly skilled. "], [4139, "2016-02-22T01:16:51Z", 0.1, "Not yet, a few more years."], [12937, "2016-02-22T00:49:08Z", 0.68, "So when AlphaGo won the game 5\u20130, it was a big deal.\n"], [17875, "2016-02-21T17:46:47Z", 0.0, "@cdob63  is correct about the awesome destructive force of innovation.  Car's weren't a better horse, Eli Whitney & Abigail Adams made a swell cotton gin, and Gutenberg's press wasn't bad either.   It's difficult to anticipate the specific tipping point but once it happens everything after it isn't the same. \n--\nThe reason I'm at 0% and not 59% is reflected in a John Maynard Keynes quote:  \u201cThe market can stay irrational longer than you can stay solvent.\u201d  For the last 12,000 years a computer hasn't bested man at Go until last October.  That's a pretty awesome feat on both accounts! Perversely, I hope I'm totally wrong on this question.  I'd happily trade my irrationality for an awesome achievement of mankind, but I have to endure the pain of being proven utterly and indiscriminately wrong to do it : ))"], [20317, "2016-02-21T17:30:36Z", 0.1, "If AlphaGo beat Lee Sedol, it would mean Go programs progressed faster in the past six months than at pretty much any other time. There's a big difference between beating a 2p and beating the world champion."], [15471, "2016-02-21T14:44:58Z", 0.65, "Going a bit lower due to ELO ratings, still believing in ML though"], [19306, "2016-02-21T13:45:36Z", 0.08, "Alpha Go current ranking estimated #279\nIf progress up to #95 rank, ELO would be 3306\nProbability of winning a game against Lee Sedol (ELO=3524) is 0,22 (http://www.bobnewell.net/nucleus/bnewell.php?itemid=279)\nProbability of winning 3, 4 or 5 time on 5 game against Lee Sedol = 0,074 rounded up"], [212, "2016-02-21T13:09:39Z", 0.15, "I don't think AlphaGo will win considering the European champion AlphaGo beat was just 2p while Sedol is 9p, a big difference. While we don't know how much AlphaGo can learn in six months, the belief among a few of the people in the Go industry seem to think that AlphaGo just doesn't have enough experience to beat Sedol. Also, AlphaGo would have to win three of five games to win, which seems like a bit of a jump from just beating a 2p player 5-0 to beating a 9p player.\nhttp://www.nature.com/news/go-players-react-to-computer-defeat-1.19255\nhttps://www.quora.com/Can-Google-AlphaGo-beat-world-Go-champion-Lee-Sedol-in-March"], [19427, "2016-02-21T02:59:17Z", 0.6, "More weight on DeepMind CEO and the computer scientists' statements. I believe them."], [19306, "2016-02-21T02:51:13Z", 0.19, "Elo difference gives Lee Sedol 93% of winning and he must win 3 times on 5"], [19306, "2016-02-21T02:07:38Z", 0.07, "ELO 3140 vs 3515 has 0,0342 ow winning, doubled considering previous progress made by AlphaGo"], [17875, "2016-02-20T20:07:12Z", 0.0, ": )"], [17819, "2016-02-20T07:06:57Z", 0.52, "I have a bit of I bias toward machine learning algos and as such I have been second guessing my intuitive feeling that AlphaGo will take it. I do however feel that the plans that the google team have started implementing after the last game (getting better help and letting AlphaGo play more games i.e. \"learn more\") might push the odds in favour of the machines. This is a very hard question to answer as there is pretty much no way of knowing how strong AlphaGo has gotten since the game against Fan Hui.  "], [17875, "2016-02-20T03:09:12Z", 0.0, ": )"], [94, "2016-02-19T23:56:39Z", 0.35, "According to [1], AlphaGo has at most a 50% chance of winning, and a normalized 45% chance of winning.  I'm increasing my odds in accordance with this."], [20193, "2016-02-19T21:57:25Z", 0.5, "It is too early for the computer to have all the moves. Hence giving 50 % "], [20247, "2016-02-19T19:42:19Z", 0.68, "Lee Sedol is ranked 5th in the world, meaning AlphaGos victory over Fan Hui (who despite being European champion, is 633rd in the world) doesn't provide as much information as it first appeared. That said, the victory was comprehensive, and the alphago team have since added FanHui to their advisory team. In addition, AlphaGo is playing around a million games every day, improving with each one. Furthermore, the alphago team are laying their own cables for the upcoming match, further increasing their computing power. Finally, the alphaGo team reports it can beat the best rival computing programs with a 4 stone handicap, something even the top professionals have been unable to do. While it is tempting to draw comparison to Kasparov vs DeepBlue (with DeepBlue losing the first game), there are vast differences. DeepBlue's previous game was a loss in an AI tournament, leading to a tie for second place. Its code was based on hard-coded logic which was being manually updated. And computing power was far less back then. AlphaGo is coming off the back of an impressive victory against a human professional, is improving every day, and has significantly more computing power, meaning it is likely to improve exponentially.  "], [19801, "2016-02-19T13:58:00Z", 0.92, "After reading Google's paper, and realizing that AlphaGo distributed has thousands of cores and GPUS, it is clear that this program will be at least 240-220x stronger than the original AlphaGo which was already able to beat a human 2 Dan pro. Neural networks have linear scaling on GPUs, and Monte Carlo Tree Search has almost linear scaling on CPU cores. Those are the two main techniques that AlphaGo uses."], [20226, "2016-02-19T12:09:50Z", 0.65, "chess has 10^120 permutations, wei qi has 10^170, computing power has grown exponentially since deep blue beat kasparov. "], [15331, "2016-02-18T20:20:12Z", 0.35, "https://www.quora.com/Can-Google-AlphaGo-beat-world-Go-champion-Lee-Sedol-in-March"], [12413, "2016-02-18T18:05:13Z", 0.68, "The previous match between AI and the Euro GO champion was 5-0 for the AI.  This champion would not win a match vs the upcoming opponent, so that takes me to  suggest it will be at least a close match.    In fact Fan Hui wasn't just beaten he was thoroughly trounced in his match he stated \"The problem is humans sometimes make very big mistakes, because we are human. Sometimes we are tired, sometimes we so want to win the game, we have this pressure...The  programme is not like this. It's very strong and stable, it seems like a wall. For me this is a big difference. I know AlphaGo is a computer, but if no one told me, maybe I would think the player was a little strange, but a very strong player, a real person.\""], [20156, "2016-02-18T07:21:31Z", 0.47, "Beating the best human player in GO is much harder than in chess. It took IBM years to battle the latter, and it will take time to really succeed at the former. It will beat Sedol once or twice but probably not more this time. "], [17875, "2016-02-18T02:57:22Z", 0.0, " : )"], [691, "2016-02-18T00:30:56Z", 0.58, "I do not bet against machines any more on this sort of Q.  Still, comes the revolution, I expect I will be in the first group the machines line up against the wall--too ambivalent, so not a reliable ally for them."], [20164, "2016-02-17T22:39:11Z", 0.25, "Like IBM for DeepBlue, Google will need this first match to collect feedback/lessons learned and update its Go engine...then it'll be ready for the second match and beat Lee Sedol (or someone of his caliber)...yet this is still an incredible achievement by Google thus far...."], [20044, "2016-02-17T14:14:55Z", 0.95, "Assigning an arbitrary value of 10 to the computational power of the first computer to defeat a grandmaster in 1988, Moore's law implies that Deep Thought had computational power of 226 on the the same arbitrary scale when it defeated Gary Kasparov in 1997. In other words, the difference between a grandmaster and one of the best chess players was about 216 units of computational power. (The difference in ELO ratings between a grandmaster and a top player like Gary Kasparov appears to be similar to the difference in ELO ratings between Fan Hui and Lee Sedol, as given by this Wired article: http://www.wired.com/2016/02/well-know-soon-if-google-can-beat-a-super-grandmaster-at-go/). "], [17819, "2016-02-17T12:31:42Z", 0.45, "https://www.gjopen.com/comments/comments/137262"], [19807, "2016-02-17T11:33:30Z", 0.2, "Upon reading the following articles, i am turning 20 to yes."], [20135, "2016-02-17T11:17:40Z", 0.68, "The input from many different parties should outweigh the strategic thinking of one."], [17819, "2016-02-17T10:42:31Z", 0.56, "I personally feel that machine learning algorithms are a very powerful tool and that the odds are in favour of AlphaGo winning. The algorithm used by it (while having some drawbacks) is very good at finding underlying relationships- taking into consideration both different strategies and the \"score\" of the position. I don't know exactly what the Google team did after the last game so I don't know what the chances are that the machine will beat a much stronger opponent. But I'd like to think that the machine will exploit any weakness that Lee makes. So for a preliminary forecast, let's start with a safe 56%. Will update after I've done a bit more research.  "], [20131, "2016-02-17T07:52:44Z", 0.75, "First of the reasons is the AlphaGo program beat the European champion by 5-0. This makes it a very strong contender in the March series. If not by 5-0, the program can at least win by 3-2. The reasons for not giving the absolute certainty of the program winning i.e the remaining 25% chance of not winning is it is possible that the Lee Sedol (a world champion) might be a tougher opponent than Fan Hui (just an European champion). It is also possible that the intermittent time allows Lee Sedol to come to know the weaknesses in the AphaGo's play.\nOverall, it is almost a certain thing that once a computer program crosses a threshold it will keep on improving and would not stop. A simple explanation is the very fist calculators could have been as fast or as slow as fastest human mathematics wizards. But, slowly they moved up the ladder and as of today no human beings is anywhere close enough. So it will be the same case even with the game Go. "], [17875, "2016-02-17T06:10:21Z", 0.0, ": )"], [767, "2016-02-17T03:06:46Z", 0.2, "Sounds like AlphaGo is just getting the hang of it.  The new computer program may need more experience playing masters in this type of game. http://www.scientificamerican.com/article/computer-beats-go-champion-for-first-time/"], [20117, "2016-02-17T00:51:04Z", 0.85, "Computers programmed thoughtfully will prevail."], [2586, "2016-02-16T23:55:26Z", 0.0, "Good Judgement is currently 53% yes, but maybe only 0.1% of forecasters even understand the rules of Go let alone have played it. They have heard alot about Google though, and about chess computers, so forecasters naively think Go is a solveable computer problem. So right here there is an over-optimistic bias for AlphaGo. BitBet gives AlphaGo only about 33% chance.  "], [1354, "2016-02-16T20:19:57Z", 0.4, "Analysis of AlphaGo's game suggests that at its previous level it would lose (that is was ranked in the 200's, and Lee Sedol is ranked much higher). Lee will also have time to prepare; on the other hand, AlphaGo will too, and its team would presumably not take the match if they didn't think thy could win."], [19807, "2016-02-16T15:08:27Z", 0.4, "I am correcting my forecast. I meant 40% yes :-) "], [19807, "2016-02-16T14:48:54Z", 0.6, "According to goRatings as of 02-14-2016  (http://www.goratings.org/ ) Lee Sedol, World Champion, is the number 4 in the world.\nFan Hui, the European Champion, defeated by AlphaGo is number 475 (and the top seeded not coming from China, Japan or Korea) ."], [20092, "2016-02-16T14:45:00Z", 0.75, "Track record already existing for AlphaGo"], [20080, "2016-02-16T11:21:08Z", 0.95, "the alphGo beat the european champion by a country mile. no reason why he won't at least beat the world champion in a five-game series. "], [19990, "2016-02-16T07:44:50Z", 0.65, "I don't think Deepmind would have entered the challenge if they didn't have some confidence that they will at least win a few games."], [20042, "2016-02-15T21:22:14Z", 0.8, "I just can't imagine a professional in the east being so much better than a champion in the west. If the European Go champion was beaten 0-5 and AlphaGo has months to improve its play I think Lee Sedol's chances are slim. Also I heard Lee Sedol has been on the top for years, so perhaps his time has come and he is not so sharp anymore. Humans playing a charismatic champion will often fail to recognize a blunder for what it is, but a computer will punish the slightest error relentlessly.\nOf the two big computer chess engines Stockfish optimizes its parameters by playing lots of games, but the world champion Komodo has been programmed with higher positional principles by a chess grandmaster renowned for his positional play. \nIn the same way you'd expect Lee Sedol to have a positional feeling that AlphaGo cannot acquire by playing itself. How broad and general are the patterns that AlphaGo can recognize in and of itself? In chess tactics always play a larger role, in Go that would be to conquer a group of stones. Go is more of a positional play than chess so it is really interesting to see if AlphaGo has provably acquired such higher positional principles. I would be disappointed if AlphaGo just defeats Lee Sedol with tactical play, but I don't know the game of Go very well so the commentators have to tell me that."], [17875, "2016-02-15T20:23:42Z", 0.0, ": ) "], [1106, "2016-02-15T11:56:34Z", 0.96, "Human get tired, Lee perhaps may beat AlphaGo in one of the first to third game, but in the five-game match, it is rather difficult for a human player to beat a cold machine 3/5 games. moreover, Lee can beat other human by studying other master player's style in previous matches, but a computer has no style, just go for probablities, which make it hard for human to beat, the human can allow no mistake in front of a computer search algorithm"], [1403, "2016-02-15T09:37:33Z", 0.98, "Deep Mind has generally been blowing people out of the water. Plus so much dev time will mean likely success."], [19106, "2016-02-15T09:29:57Z", 0.2, "I would put the chances of the October version of AlphaGo beating Lee Sedol in a game at 10%, based on google's estimate of its ELO (3140) and GoRatings' estimate of Lee Sedol's ELO (3500). That means the probability it wins a match is only about 0.1% if we believe the ratings. I think even the October AlphaGo's chance are perhaps slightly better than that."], [17875, "2016-02-15T07:37:27Z", 0.0, "the most important questions I have are:\n1) learning rate of AlphaGo since October\n2) perceived benefit of using professional games for training on the actual performance  (e.g. identifying circumstances of opportunity, ability to recognized strategic decisions, balancing chance of winning vs best possible move at the time, aggressive vs passive play)\n--\nupdate: I LOVE that I got 2 downvotes, lmao : ))  "], [60, "2016-02-15T05:09:53Z", 0.14, "Raising from 8 to 14%."], [14327, "2016-02-15T04:49:28Z", 0.75, "Putting the odds back up. "], [19936, "2016-02-15T03:32:25Z", 0.75, "My friend George works on it and is working hard"], [17875, "2016-02-15T02:11:56Z", 0.0, ": )"], [8183, "2016-02-14T22:17:23Z", 0.15, "I do not believe that AlphaGo  is intuitively intelligent in any way shape or form and the game has a lot of intuitive intelligence in it that Sedol has. I didn't rate the chance down to zero, because accidents can happen."], [10785, "2016-02-14T20:45:20Z", 0.75, "Go is a mathematical game with a limited set of solutions, therefor possible to calculate the winning moves. A - well programmed - computer can do this better/faster than a human being."], [19965, "2016-02-14T15:41:33Z", 0.08, "The degree to which Lee Sedol is better than Fan Hui suggests to me that the AI can't be improved that much in the period of time between the matches.  But it's also not clear how much better AlphaGo is than Fan Hui."], [19380, "2016-02-14T10:50:42Z", 0.22, "Decision points... \n1. Is Go a type of computing problem where a computer can conceivably be better at than all humans?\n2a. If so, has AlphaGo reached that level of capability yet? \n2b. If not, has it at least reached a level to beat Lee Sedol?"], [909, "2016-02-14T05:45:41Z", 0.85, "They've already beaten Fan Hui, another Go master. I don't think this next match going any different. People forget that mental fatigue is a thing.  Garry Kasparov lost to Deep Blue when he got tired, the same thing will happen here as well. "], [709, "2016-02-14T04:50:50Z", 0.7, "I don't know much about Go, but I do work in machine learning. "], [19951, "2016-02-14T03:24:16Z", 0.23, "Articles I have read indicate that the level of the Go program is not high enough yet. I have little knowledge of Go, but not much reason to disbelieve the articles."], [17875, "2016-02-13T21:40:29Z", 0.0, ": )"], [19427, "2016-02-13T01:34:58Z", 0.4, "Re-weighing DeepMind teams' statements as being stronger evidence that they will win."], [3320, "2016-02-12T21:54:49Z", 0.45, "I continue to rate AlphaGo's chances slightly better but still not quite at the Lee Sedol level.  Here's a useful link from a Go player with a lot of experience in programming computers to play the game.  https://smartgo.com/blog/lee-sedol-vs-alphago.html.  Here's his conclusion, stripped of a graphic showing a board position:"], [19218, "2016-02-12T18:10:03Z", 0.2, "Readjusting my estimate downwards to reflect:"], [18294, "2016-02-12T17:04:20Z", 0.45, "I don't see a 5-0 win for the computer in this match.  But the world champ has played enough matches that the program can be optimized to some degree for the match in question.  That is enough of an edge that I think the machine has a slight edge."], [17875, "2016-02-12T16:19:15Z", 0.0, "I was originally at 75% given what I know about AI. I changed to 0% to over compensate for being a little high early on"], [19857, "2016-02-12T08:28:23Z", 0.85, "Merit so far"], [17875, "2016-02-12T02:26:45Z", 0.0, "I was originally at 75% given what I know about AI. I changed to 0% to over compensate for being a little high early on"], [19427, "2016-02-12T01:50:21Z", 0.36, "Simple Bayes' theorem calculation:"], [3320, "2016-02-11T16:08:54Z", 0.42, "I'm increasing my bet just slightly in favor of AlphaGo.  I'm impressed by the arguments that AlphaGo can continue to learn faster than any human, so can be expected to be even stronger in March.  I've thought about the report that AlphaGo was trained using only amateur games.  If so, why might that be, given that so many professional games have always been available?  I can think of one reason.  Amateurs make errors whose adverse consequences are often obvious after only one or a very few moves.  So if you're showing someone what not to do, review of games by weaker players makes sense.  Professionals almost never make outright blunders.  They lose by making suboptimal moves whose consequences may not be obvious and often not even identifiable without careful post-game analysis.  However, AlphaGo may well be at the point where it can learn from subtler mistakes.  If that's plausible, the program may well win."], [19801, "2016-02-11T06:30:06Z", 0.69, "Checkers was solved in 2007, by Chinook. Tic-Tac-Toe and Connect 4 are also solved games. Stockfish's strength is beyond compare at chess. It was only a matter of time before Go fell, and AlphaGo is demonstrating an approach that can deliver the goods. The combination of neural networks and Monte Carlo has already made Alpha Go the strongest Go program that ever existed. Out of 500 games, AlphaGo lost only one."], [773, "2016-02-11T03:03:08Z", 0.15, "Bsed on @einsteinjs comment\nhttps://www.gjopen.com/comments/comments/129537"], [17875, "2016-02-10T17:22:47Z", 0.0, "I was originally at 75% given what I know about AI.  I changed to 0% to over compensate for being a little high in the beginning and need to stay here a couple more days. "], [16160, "2016-02-10T15:34:56Z", 0.8, "AlphaGo already has beat Fan Hui, the European 5/5 games in a tournament format.  "], [15590, "2016-02-10T12:30:11Z", 0.09, "Update: Did the probabilities, messed up subtraction.\nAssuming a probability of wining of about 87% if the 5-0 match was not a fluke, but a 50-50 result. We could estimate the elo rating of Alpha Go to be about 3300, a bit higher than stated in the original paper. Chess programs improve about 70 elo per year, so it COULD be estimated to have improved about 30 points by then. The first win was expected to 2020, but Deep Mind managed it in 2016  That is 3330 vs 3522 for Sedol. Still a 192 point diference. \nBut: the biggest uncertainty is how much can AlphaGo improve in this few months. I does seem that throwing more raw computer power can increase ELO a bit, but it is not clear by how much. I believe I can be underestimating the rate of improvement. let's say it can improve 5 times faster. That would be a decent ELO 3450 vs 3522\n72 point difference translate in about 25% per match. = 9% per game"], [14327, "2016-02-10T05:59:08Z", 0.52, "Thank you, @rfgarcia and @WJK for your comments concerning scores and probabilities. \n@adamgbell and @johnfdhartman also have excellent points. "], [5001, "2016-02-10T05:32:05Z", 0.25, "Previously, I underestimated the uncertainty about how and how fast AlphaGo can improve. So correcting. "], [19427, "2016-02-10T03:38:33Z", 0.45, "Updating from 40% to 45%."], [18888, "2016-02-10T02:15:37Z", 0.02, "Thanks to @rfgarcia for the catch from the original paper: http://www.gjopen.com/comments/comments/129458"], [19617, "2016-02-10T01:27:41Z", 0.65, "Based on what AlphaGo has achieved, I'm quite optimistic that it will win. "], [15590, "2016-02-09T23:47:53Z", 0.2, "Assuming a probability of wining of about 87% if the 5-0 match was not a fluke, but a 50-50 result. We could estimate the elo rating of Alpha Go to be about 3300, a bit higher than stated in the original paper. Chess programs improve about 70 elo per year, so it can be estimated to have improved about 30 points by then. that is 3330 vs 3522 for Sedol. Still a 92 point diference. That is about 20% per match. "], [14268, "2016-02-09T21:43:11Z", 0.4, "Go is a hard game, and there's a big difference between 700th and 1st ranking in playing it. The team may be able to bridge that gap in a few months, but Deep Blue lost the first match with Kasparov and I think it's likely the top player here will win also, "], [19218, "2016-02-09T21:28:35Z", 0.4, "Before I said 27%, reasoning (a) that Google was silent and Sedol was confident and (b) Google's incentives are if anything to challenge before it's likely to win. "], [1111, "2016-02-09T19:55:02Z", 0.9, "Quite certain that it will. "], [19390, "2016-02-09T19:34:20Z", 0.3, "Based on expert game analysis, AG seems to have approx 7th dan level. According to ELO ratings, the chance of Sedol winning would be around 80%. But, AG has probably become stronger over the last 5 months (since defeating Fan Hui). So I subtract 10% (wild guess) in order to adjust for this learning curve"], [17875, "2016-02-09T18:53:23Z", 0.0, "AlphaGo's ability to scale on hardware and Googles ability to make it scale on programming has really given AlphaGo a unique chance to increase it's learning rate against tougher professional opponents where it is counter-intuitively likely to do even better than against worse players (it's optimized for winning % not the best move).  So I'm capitulating that I lost this question but I'll take one for the team and improve others scores"], [19381, "2016-02-09T17:22:45Z", 0.3, "https://www.quora.com/Can-Google-AlphaGo-beat-world-Go-champion-Lee-Sedol-in-March"], [10930, "2016-02-09T14:29:17Z", 0.45, "@nicholas found better information on the ELO ratings, via hacker news (https://news.ycombinator.com/item?id=10981679) :"], [691, "2016-02-09T14:13:46Z", 0.61, "The thing about AI, I am reliably informed, is that sometimes the machine gets smart even faster than its programmers expected it to.  And sometimes it's slower.  Even though this one hasn't played officially in a while, it has presumably been gulping down data, including game play-by-plays, much faster than you or I care to know about.  In such matters I have taken to siding with the machine.  Luckily I shall be safely dead before we all find out whether they make a better job of it than we have.  "], [19538, "2016-02-09T13:19:42Z", 0.15, "Go software is competing at professional level for quite a while now (~ 4 Dan), but is still quite a bit away from the very top. In chess, it took longer from competing at grandmaster level to beating Kasparov. That said, Google is throwing a lot of money at AI research, and has exceeded expectations in the past."], [19453, "2016-02-09T11:00:29Z", 0.12, "AlphaGo's current rating is widely reported as around 3140- this bears out, as it won 5 out of 7 matches against Fan Hui (Whose 2970 ELO would make him about 27% likely to win any game against a 3140 opponent, making winning 2 out of 7 a fairly reasonable outcome). Lee Sedol's ELO appears to be 3515, which means that he has a roughly 90% chance of expected victory against AlphaGo in any one game."], [436, "2016-02-09T04:50:26Z", 0.53, "I found an interesting analysis from a Go professional, who critiqued (and complimented) AlphaGo's play in the Fan Hui match. There's a decent chance that Fan Hui could've won a game or two had one single move been different (the sort of thing Lee Sedol would never miss)."], [19527, "2016-02-09T04:25:14Z", 0.2, "AlphaGo clearly isn't there yet.  I'm skeptical it can traverse the rest of the difference in 5 months; especially since the previous big leap was insight-based rather than brute-force-based.  To keep up that speed of improvement they'd need another insight; I don't think that massively parallel power will be enough.  I don't yet have reason to believe AlphaGo's programmers are in that special class that only says \"We expect to win\" in possible worlds where they're mostly set to win - that's a rarefied level of honesty and rationality.  AlphaGo may well win in 2017 or 2018, but a 0-5 shutout would not surprise me here."], [16025, "2016-02-09T03:24:06Z", 0.55, "Computers have played Go and beaten amateurs but, before Google's victory against the French champion, experts had predicted that it would take another 10 years until a computer could beat the world's best Go professionals. This prediction was clearly wrong and people are underestimating Google's AlphaGo."], [773, "2016-02-09T03:10:26Z", 0.25, "In Gary Markus discussion of the hybrid neural net / decision tree approach being used:\nhttps://backchannel.com/has-deepmind-really-passed-go-adc85e256bec#.bz6s0q2c7"], [19515, "2016-02-09T01:35:39Z", 0.9, "The tech giant can spare plenty of resources to ensure its victory."], [19476, "2016-02-08T23:43:38Z", 0.15, "- The last significant evidence suggests supercomputers don't always win at the first challenge (Kasparov vs Deep Blue 1996), meaning they are perfectible. \n- Most Korean professionals favor Lee Sedol (they can better assess the difficulty of programming Go algorithms than I do).\n- Lee Sedol is confident he can win.\n- Go isn't chess (10^761 vs 10^120 possible games).\n- Lee Sedol has actual evidence on the power of AlphaGo since the computer already played Fan Hui and can accurately estimate its capability of beating it."], [10930, "2016-02-08T23:11:22Z", 0.55, "Some Experts:\nFan Hui has the rank of 8 dan, 10 levels below the top professionals such as Lee Sedol 9P. Lee should have no trouble winning in March. - Edward Cherlin"], [19218, "2016-02-08T21:12:33Z", 0.27, "1. Sedol thinks he can win, and he has much better information than I have."], [5083, "2016-02-08T19:48:29Z", 0.7, "I give a creative well-trained human a 30 per cent chance. ingenuity can crap on a computer."], [19486, "2016-02-08T19:19:37Z", 0.65, "Beat a lower level pro who had not played professionally in a few years. Lost 2 informal games before 5-0 formal."], [16223, "2016-02-08T18:51:06Z", 0.99, "The effort was making a machine that can win. They have done that. At 5 games, I give the edge to the machine because it is more likely Lee Sedol makes a mistake. At one game I would be less convinced (though still think the machine would take it). "], [17883, "2016-02-08T17:42:43Z", 0.6, "Deep Blue beat Garry Kasparov 3.5/6 games in 1997. Kasparov had a chance to win but made a mistake. The Komodo chess engine recently beat US #1 Hikaru Nakamura 2.5/4 games. The average winning chances of the machines in both the Kasparov and Nakamura matches was 60%. It seems likely that Google's AlphaGo will do something similar: Edge out Lee Sedol by capitalizing on one of his few mistakes and turning it into a decisive advantage 2/3rds of the way into the match."], [18762, "2016-02-08T17:05:30Z", 0.67, "Lee Sedol has a 72% winning percentage. Assume Sedol's losses are to slightly better than average expert players. Clearly Alphago is better than an average expert, having beaten Fan Hui 5-0.  How much better? maybe only slightly better, but also up to many multiples better or even unbeatable. the math of Sedol probability losing may matter, but for me the more important question is how good is AlphaGo compared to him and the range out outcomes is a) large and b) the majority of these outcomes are that AlphaGo is better and c) some portion of these outomes makes it unbeatable by Sedol. "], [19470, "2016-02-08T16:23:41Z", 0.1, "Looking at the games, Alphago showed some serious mistakes that won't be easy to fix.  While it's general fighting is likely to be stronger than Lee Sedol's, it makes too many bad exchanges."], [19427, "2016-02-08T16:22:47Z", 0.4, "I made a $500 bet at even odds that Lee Sedol will win the match against AlphaGo. If I win, I intend to donate my winnings to one of GiveWell's top charities (probably the Against Malaria Foundation)."], [19464, "2016-02-08T15:29:53Z", 0.97, "1. Google has vast resources in the form of it's server farms and the machine learning expertises of it's employees.\n2. Google has a long history of getting things right when it comes to ML.\n3. AlphaGo already won 5-0 against a 3-time European champion. That's not even close, it's exponentially more meaningful than winning 3-2. Both Google and Fan Hui have a strong incentive to protect their reputation, so despite the aforementioned game being behind closed doors, there was probably no payoff involved."], [17875, "2016-02-08T14:50:05Z", 0.01, "@bpoppe  thanks for your analysis today, it was helpful to understand why someone would be at 70%.  Please explain further how you decided on 70% and not 65%-75%."], [15318, "2016-02-08T14:06:59Z", 0.7, "Given what we've seen from Google, IBM, etc. in machine-learning, and the fact that AlphaGo recently beat the 3-time European champ.  From what I can find, Lee Sedol has not played Fan Hui (the European Go champ which AlphaGo recently defeated), which would make this analysis easier in my opinion.  I did not go to the lengths of Sedol beat X who beat Fan (sports enthusiasts would tell you this doesn't matter anyway).  I still think it's reasonably likely, given that the European champ recently went down."], [17695, "2016-02-08T12:29:04Z", 0.45, "It's Google, they're good, but they never totally win the first time."], [19449, "2016-02-08T09:45:24Z", 0.45, "AlphaGo's current world rank is estimated in double digits. A win for AlphaGo is plausible, but I can believe the world's top Go player has faculties it can't yet accommodate."], [16932, "2016-02-08T09:19:52Z", 0.31, "early days, and so far it has beaten only #250-odd ranked player..."], [18871, "2016-02-08T07:55:57Z", 0.79, "There is pattern when humans play which can be learned by the AI which it 79% chance to win. But given that the AI has not been pre-programmed to win there s a 21% chance for Sedol to win."], [12482, "2016-02-08T07:29:07Z", 0.05, "(1) It usually takes several trials before a computer bits the human champion.\n(2) The IBM program that bit Kasparov used a lot of historical data about games. As far as I know there is no similar database in regard to Go.\n"], [12107, "2016-02-08T03:49:17Z", 0.75, "The use of instinct to make a choice from a very large pool of choices is over-rated. The Google 'AI's' ability to learn its opponent's 'instinctual plays' should give it an advantage."], [18489, "2016-02-08T01:57:04Z", 0.25, "See http://www.numerama.com/sciences/143423-le-grand-combat-de-lia-de-google-contre-le-champion-de-go-sera-diffuse-en-direct.html. Also : http://www.wired.com/2014/05/the-world-of-computer-go/"], [11242, "2016-02-08T00:42:48Z", 0.55, "The speed of AlphaGo's learning should prepare it."], [14133, "2016-02-08T00:07:28Z", 0.75, "Google wouldn't agree to the deal if it was not reasonably confident of winning."], [15785, "2016-02-07T23:47:08Z", 0.08, "I read the person, who was beat isn't that good. It took longer for Deep Blue to win than the first match against Kasparov. I expect a similar outcome."], [8873, "2016-02-07T23:40:37Z", 0.25, "Software isn't good enough yet."], [3320, "2016-02-07T23:13:57Z", 0.36, "There is, by the way, a slight ambiguity in the word \"beat\" in the question.  I'm interpreting it as \"win the match -- i.e., win at least 3 of 5 games.\"  However, if \"beat\" means \"win even one game,\" I'd change my \"yes\" percentage to about 70.  Perhaps the GJ monitors should clarify."], [5001, "2016-02-07T22:28:26Z", 0.1, "Going up because I just realized that a training set is likely to be based on pro games, not on the amateur online database they used earlier."], [14307, "2016-02-07T21:27:03Z", 0.7, "I looked at the timeline of the progression of chess-playing computer programs, and am losing confidence in how fast a Go program might progress. "], [131, "2016-02-07T21:16:37Z", 0.02, "Lee Sedol is going to smash AlphaGo. "], [3467, "2016-02-07T20:50:13Z", 0.6, "It seems like the game is based mostly on numerical calculations."], [19413, "2016-02-07T20:41:56Z", 0.4, "The first time a chess computer beat a pro human was in 1989. It beat the world champ in 1997. \nJust because a go computer won once, does not mean that it will win again."], [1450, "2016-02-07T20:16:49Z", 0.2, "I put the prior somewhere below 10% based on what some other commentators have stated about the relative Elo ratings.  I then adjusted for the level of uncertainty and AlphaGo's learning since those games.  "], [19403, "2016-02-07T18:35:01Z", 0.55, "I have read several compelling analyses about the skill difference between the prior opponent and the current opponent.  The consensus for them seems to be that Lee Sedol is not merely a slightly better player, but an entirely different class."], [19386, "2016-02-07T12:54:50Z", 0.85, "!"], [1629, "2016-02-07T12:00:38Z", 0.67, "The AlphaGo looking very strong, very good chance it will beat Lee Sedol in March, but untill I find out more about Go I'm going for the high 60ies untill I find out more."], [15621, "2016-02-07T10:29:36Z", 0.59, "As it learns by playing itself the rate of improvement should be very rapid. Google unlikely to have offered challenge unless they are happy that it will at a minimum be competitive. They probably have some idea what level Sedol is at, but we have really no idea how good or potentially good AlphaGo is."], [5001, "2016-02-07T06:28:56Z", 0.05, "Affirming. A 9p-level professional not very impressed: \nhttps://www.youtube.com/watch?v=NHRHUHW6HQE#t=1h20m00s"], [14643, "2016-02-07T02:33:35Z", 0.22, "I thought AlphaGo's result against Fan Hui (counting points difference at end of each game) was quite close, way closer than the 9p vs 2p gap. I'm guessing the next match will be 4-1 or 3-2, Lee. AlphaGo probably has processed all the real game data out there already, and improvements through playing itself I think will be much slower than learning from real past games."], [18845, "2016-02-07T02:29:48Z", 0.68, "Based on the stats located in the Google blog post about the topic, AlphaGo can predict the moves of an opponent 57% of the time.(http://www.siliconbeat.com/2016/02/05/googles-alphago-to-take-on-world-champ/) This led me to an initial baseline.  Along with this,  I used the information from an article published in the Nature International Weekly Review of Science that stated  the AlphaGo program boasts a 99.8% winning rate against other Go programs.(http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html) "], [14841, "2016-02-07T02:12:26Z", 0.33, "The player beaten 5-0 is quite a way below the elite level of GO, however not that far behind, so I rate AlphaGo with 1 in 3 chance."], [14877, "2016-02-06T23:43:41Z", 0.3, "Lee Sedol is the best player in the world. He has the advantage of knowing that there is a computer program capable of playing at elite level (Fan Hui was very surprised at being beaten). One could surmise that Lee will be ready for AlphaGo. On the other hand, AlphaGo will have improved in the meantime."], [17875, "2016-02-06T21:23:38Z", 0.05, "AlphaGo plays better against tougher opponent and Lee knows his opening is the weakest part of his game. Should be fun to watch"], [18914, "2016-02-06T19:48:24Z", 0.35, "https://www.youtube.com/watch?v=dmR0BiGvXUw (Chinese Pro commentary on 2 of the games between AlphaGo and Fan Hui in Chinese)"], [19343, "2016-02-06T19:02:02Z", 0.6, "I don't think Google would enter the match if it didn't thing it had better than even odds of winning. I also think that the system performed extremely well in its last match, and Google will take the intervening time to port it onto yet more powerful GPU clusters, deepening its raw search performance.   "], [19333, "2016-02-06T18:33:42Z", 0.4, "AlphaGo won eight of its ten games against Fan Hui.\nLee Sedol would probably not lose one game in ten against Fan Hui; AlphaGo (as of its match against Fan Hui) is notably weaker than Sedol. Starting guess: about 20% chance per match to win."], [19332, "2016-02-06T16:59:43Z", 0.99, "It has more capacity for process and thought - in a manner of speaking - Skynet?"], [19311, "2016-02-06T15:25:42Z", 0.35, "There is really not enough info on this available (or I didn't found it). AlphaGo reportedly didn't use recordings of professional games for training before, but it would be really strange if Google didn't try to improve it in that way. Although Lee Sedol is much stronger than Fan Hui, I read that he's quite emotional and random losing in one of two first games could really hurt him to the following games..."], [14394, "2016-02-06T09:57:56Z", 0.08, "- Lee Sedol is a much stronger player than Fan Hui. Fan Hui has a very low chance of winning a single game against Lee Sedol\n33% There's a chance AlphaGo is actually not (much) stronger than Fan Hui despite the 5-0 win. 0% win chance if this is the case for AlphaGo\n67% AlphaGo is indeed much stronger than Fan Hui split as below:\n      54%  I still find it far more likely than not that the AI is not yet on par with  Lee Sedol. 0% win chance if this is the case for AlphaGo\n      9% AlphaGo is roughly on par with Lee Sedol. 50% win chance if this is the case\n      4% AlphaGo is (much) stronger than Lee Sedol: 95% win chance."], [15471, "2016-02-06T09:54:34Z", 0.75, "Maybe this prediction is mostly a reflection of my believe in technology vs intuition. But google tends to do a good job at such \"AI\" projects."], [436, "2016-02-06T08:50:36Z", 0.62, "As has so often happened, I wish I truly understood Go, and could tell how close the matches were between AlphaGo and Fan Hui. Fan Hui is 600 Elo points below Lee Sedol, so the match isn't as informative as I'd expected (I knew Go was regionally lopsided compared to chess, but this is ridiculous). I do wish that I knew how much \"worse\" AlphaGo played in that match than we'd expect Lee Sedol to -- it's possible that its true strength will only reveal itself against a proper opponent."], [19096, "2016-02-06T06:42:45Z", 0.43, "Go is considerably more difficult than chess for computers due to exponentially larger number of positions, so it's remarkable that AlphaGo has already defeated a 2 dan player just 5 months ago 5-0. But Lee Sedol is a 9 dan world champion, so that, plus the game's complexity makes me think the human has the edge. "], [17875, "2016-02-06T05:32:21Z", 0.05, "Goratings.org puts Lee sedol's ELO at 3519 and a couple posts on this IFP point out the Google paper estimates AlphaGo ELO rating at 3140 back in October."], [60, "2016-02-06T04:26:49Z", 0.08, "No change."], [19288, "2016-02-06T03:35:53Z", 0.73, "Google is very good at this sort of thing. "], [19273, "2016-02-05T23:53:24Z", 0.65, "Since it won 5-0 against the European champion, and since Google has some reputation riding on this, I'd say they'll make sure they've got good odds"], [19255, "2016-02-05T22:43:43Z", 0.08, "Google estimates the elo rating of AlphaGo to be 3140. Goratings.com estimates the elo rating of Lee Seedol to be 3516. Assuming that these ratings are accurate, there is about a 10% chance that AlphaGo will win each individual game and less than 1% chance that it will win the five game match. Elo ratings tend to be quite accurate, but accounting for the possibility of error in the ratings and the possibility that Google can significantly improve AlphaGo through algorithm changes, additional learning, or by running it on much more powerful hardware, I will make a quite liberal estimate that AlphaGo has an 8% chance to win the match."], [14761, "2016-02-05T21:50:16Z", 0.35, "Given the unpredictability and range of possible moves the computer needs more experience against top rated players to consistently beat them."], [2, "2016-02-05T21:25:17Z", 0.25, "No change.  Just stimulated by other people's comments.  I see a lot of forecasters cite additional improvement/learning by AlphaGo.  It's interesting what the learning rates of AlphaGo is.  As I understand it, on chess computers, the improvements mainly came from throwing more processing power at the program.  "], [19122, "2016-02-05T20:50:59Z", 0.95, "The difference between 2 dan and 9 dan is 4 stones ( if i got this correct ) , and AlphaGo has beaten other programs with just this much handicap ( according to their website ) . Now since Zen ( other go program) has beaten a 9 dan at 4 handicap , its highly likely that AlphaGo will beat Lee Sedol . I have to detract some percentage because of AlphaGo`s conservative playstyle .\n"], [706, "2016-02-05T20:30:27Z", 1.0, "It already beat a human and its been 'learning' since then.  Mr. Sedol has no chance."], [14307, "2016-02-05T19:15:45Z", 0.9, "One of my friends who is a borderline professional go player mentioned that he is confident that the program is going to win, based off of how the other professional match went, and based off of the kind of tactics the computerized player has available to it.  "], [651, "2016-02-05T18:53:32Z", 0.1, "The differences in ratings, even granting the program's learning potential, suggests a low probability for the March match.."], [73, "2016-02-05T17:50:05Z", 0.36, "-3, part 1 is right 57% of time up from previous 44%.  Taking three off, assuming (without any facts to back me up) it needs to be at 70% to beat 9d player, and the 1m games it plays a day are not enough to get there.\n\"The program involves two neural networks, software that mimics the structure of the human brain to aggregate very simple decisions into complex choices, running in parallel. One, the policy network, was trained by observing millions of boards of Go uploaded to an online archive. Using those observations, it built up a predictive model of where it expected the next piece to be played, given knowledge of the board and all previous positions, that could accurately guess the next move of an expert player 57% of the time (compared to a previous record of 44.4% from other groups). This \u201csupervised learning\u201d was then backed up by a bout of \u201creinforcement learning\u201d: the network was set to play against itself, learning from its victories and losses as it carried out more than 1m individual games over the course of a day. The policy network was capable of predicting the probability that any given move would be played as next, but the system also needed a second filter to help it select which of those moves was the best. That network, the \u201cvalue network\u201d, predicts the winner of the game given each particular board state.  from http://www.theguardian.com/technology/2016/jan/27/google-hits-ai-milestone-as-computer-beats-go-grandmaster/"], [19183, "2016-02-05T16:44:08Z", 0.75, "The previous matches were at a bit of a handicap, but it won 5/5 and has made tremendous progress in a short period of time without the kind of active management of the Deep Blue chess program.  I suspect it's simply learned to be a better Go player than humans are capable of."], [19173, "2016-02-05T16:30:06Z", 0.24, "The recent high-profile computer-go victories have been against players ranked a ways from the top.  Computer-go is developing, more quickly than anticipated, but such development in such short time would be pretty astounding."], [4288, "2016-02-05T15:47:10Z", 0.64, "This is difficult - I am an avid Chess player, but not a Go player; so my forecast is likely misinformed. But based on how the AlphaGo is programmed to process information, Lee Sedol will be playing the accumulated expertise of all Go players (based on a historical archive of previous Go matches). This is similar to IBM's Deep Blue approach, but Google's is more advanced, as its not programmed through brute force (inputting every game), rather is utilizes a technique of Deep Learning that enables the program to 'learn' from this historical data set AND identify new emerging patterns that may have not already been recorded or observed in a Go Players' strategy.  Additionally AlphaGo does not have a stylistic form of play, making Sedol's preparation for the program difficult. I think @KillerDucky forecast is important to observe"], [18967, "2016-02-05T15:22:49Z", 0.2, "Google's paper estimates the strongest version of AlphaGo in October had an Elo rating of 3168, calibrated to the scale at goratings.org. Lee Sedol is 3516, giving AlphaGo a 12% chance in each game, less than 10% to win a BO5. The big question is how much did it improve since October, and that's hard to say.\n"], [110, "2016-02-05T13:34:18Z", 0.05, "Low chance of this happening right now."], [19127, "2016-02-05T12:09:51Z", 0.4, "Sedol elo 3600 ago current elo 3100. Optimistic to make another leap."], [19126, "2016-02-05T12:06:09Z", 0.65, "AlphaGo learns fast"], [10039, "2016-02-05T10:15:06Z", 1.0, "Alpha go plays thousands of games in a day and learns in the process. Alpha go at the end of the tournament will not be same as the alpha go at the beginning."], [18920, "2016-02-05T09:47:03Z", 0.1, "I found a really good blog post yesterday on this very subject by Anders Kierulf. His perspective is interesting because, next to being a decent go player, he has been involved with computer go programming for many years. He offers a few good links as well, in particular an overview in .pdf from the Britisch Go Association. Please read: https://smartgo.com/blog/lee-sedol-vs-alphago.html"], [19074, "2016-02-05T06:06:37Z", 0.05, "The gap between the level of skill in the player that AlphaGo beat vs Lee Sedol is absolutely enormous. I think it's highly unlikely that AlphaGo can beat one of the top-ranked pros."], [17820, "2016-02-05T01:17:52Z", 0.55, "good start by the program beating teh european champ.  Just too much horsepower for a human brain and AI technology has come a long way."], [15914, "2016-02-04T23:41:22Z", 0.7, "Google mines the human brain. They have his info already."], [2010, "2016-02-04T23:41:00Z", 0.0, "easiest prediction of my life"], [17875, "2016-02-04T23:18:00Z", 0.05, "AlphaGo having information about the Lee while Lee knows very little about AlphaGo is probably the largest disadvantage. AlphaGo can effectively play Lee a million times just to find ANY pattern, any tendency, or any strategy that will result in a better opportunity for winning. For example:  Let's say two players, A and B, play each other 100 times.  In the beginning, A is winning 75% of the games, but after 10 games, B realizes A has a flaw in their play and starts to turn the tables, winning 75% of the games from game 11-100.  So, who is the better player?"], [18888, "2016-02-04T23:03:35Z", 0.76, "This is an update from my previous prediction of 91%."], [19031, "2016-02-04T20:32:07Z", 0.75, "Go is a game where most moves are known to be good or bad.  The process is to not miss a good move and avoid making a bad move.  This skill is better performed by a routine that structurally examines every possible move and ranks them.  Humans tend to move before exhausting analysis of all possible alternatives.  "], [94, "2016-02-04T18:28:13Z", 0.15, "My sense from other commenters is that AlphaGo's victory over Fan Hui says almost nothing about how likely it is to win against Lee Sedol, given the difference in quality between the two players.  At the same time, knowledgeable commenters (such as @einsteinjs, @Jean-Pierre, @GJDrew, and @Dima-K) seem to be giving low estimates.  My sense is that AlphaGo could win, but it would take a large improvement that is unlikely to occur."], [17875, "2016-02-04T14:45:37Z", 0.74, "To take a straight outside -> in Tetlock best practices approach to forecasting this question I think @balakirev has hit the nail on the head.  \n--\nWe need great questions, the responses to which have the propensity for fairly accurate forecasts: https://en.wikipedia.org/wiki/Precision_questioning\n--\nBig Picture\n  --> AlphaGo was created by DeepMind which was purchased by Google 2014.  It wasn't till 2015 that they started in earnest on this problem.\n  --> I'm not an AI expert but sufficiently knowledgeable to claim:  Historical examples such as chess don't uses current AI paradigms therefore are not comparable.\n  --> I'm suggesting we call the \"modern era\" for comparable cases to be those after 2010 for evaluating learning rate of AlphaGo (i.e.Watson, or otherwise)\n  -->  AlphaGo's original corpus and methodology to begin was mimicking human play by attempting to match the moves of expert players, using a database of around 30 million moves from recorded historical games (AlphaGo wiki). Then AlphaGo played itself over 1,000 million times as non-supervised reinforced learning  so that's the base or bare minimum established knowledge basis upon which will improve.\n  --> That process culminated in a BENCHMARKING game against the European Champion so as to determine, evaluate, and focus it's learning path\n  --> The next step is to begin SUPERVISED reinforced learning targeting specific facets of it's game to improve performance, which is probably occurring now\n  -->  AlphaGo has a record of 8-2, started in 2015, and is scheduled to play in 2 months\n--\nNarrowing down to a forecast"], [18992, "2016-02-04T07:13:53Z", 0.05, "AlphaGo won a pro who would not stand a chance against Lee Sedol at all, so basically there no real information available this. But we don know some issues with MCTS programs have not been solved and Lee Sedol is the player to steer game in huge whole board battle with constant threat of multiple ko-fights.  "], [10783, "2016-02-04T05:41:57Z", 0.0, "Ten years all of a sudden crammed into this one tournament? \nTwo computer scientists in the article say they are confident that Sedol can beat AlphaGo. \nSedol himself is confident. \nThe tools are not new but the integration of it is. \nI think in the future it is possible. But it just seems as though both computer experts and Go Players are confident Sedol can win. \n"], [15443, "2016-02-04T04:22:22Z", 0.92, "The neural networks provided in this algorithm already has defeated a European champion. Neural networks nowadays have spooky ability to learn quickly and learn well."], [17875, "2016-02-04T03:25:17Z", 0.75, "Does anyone think it's odd that the closing date for this is  APRIL FOOLS day?"], [18969, "2016-02-04T01:20:19Z", 0.33, "It took many years for chess computers to beat very strong human players (late 1960's to 1980's).  I am going to assume creating an computer program (AI?) to beat a human at Go is similarly complex to creating a computer program (AI?) to defeat a human at chess.  Even accounting for a Moore's law type of effect which may accelerate AI development in the intervening years, I don't think even Google can go from beating its first human who was a strong player, to beating a player on the level of Lee Sedol.  "], [14253, "2016-02-04T00:39:11Z", 0.5, "While working today I had https://www.youtube.com/c/USGOWeb on in the background. A video in which Myungwan Kim 9p analyzes some of the games between Fan Hui and Alpha Go. Thanks for that link, @Wund. "], [13361, "2016-02-04T00:34:05Z", 0.15, "Google's AlphaGo sounds like an amazing development in AI that will only get more impressive over time (Wired: http://www.wired.com/2016/01/googles-go-victory-is-just-a-glimpse-of-how-powerful-ai-will-be/). That said, it beat the European champion who was ranked 633rd in the world without a handicap. That doesn't mean it's good enough to beat the guy ranked 5th in the world. Programming AI is challenging, & a lot can go wrong (e.g. AlphaGo needs an internet connection & a lot of processing power - Google's laying its own fiber). Given all the hype - and that everyone points out how experts predicted an algorithm to beat humans at Go was 10 years away, I think Sedol has the advantage, at least in 2016. I wouldn't be surprised if AlphaGo wins one of the five matches - but it would have to improve considerably between now and April to take 3+ out of five."], [15477, "2016-02-03T23:22:46Z", 0.35, "No handicap.  "], [14027, "2016-02-03T22:14:56Z", 0.8, "Google will not want to lose this one.  And they have some VERY smart people."], [691, "2016-02-03T21:18:40Z", 0.78, "Speaking strictly as a human, it's been fun being the smartest entity on the planet for a long time, but them days is over.  The consolation, decades or so from now, will be that we outsmarted ourselves and were not outdone by anyone else.  I suspect the machines will on the whole do a better job than we have of running things, but I fully expect to be dead before that question is definitively settled. (Once again, total lack of accountability triumphs over common sense, or personal preferences, or humanity's hopes and dreams, or anything else.)"], [16292, "2016-02-03T19:58:25Z", 0.64, "AlphaGo is a *really* good algorithm. As in, it's beaten every other Go algorithm in every game they've played. It also beat the European champion Fan Hui *5-0*, which is totally unprecedented. Previous algorithms could only beat strong amateur players, and were totally outclassed by top players."], [16292, "2016-02-03T19:53:07Z", 0.56, "AlphaGo is a *really* good algorithm. As in, it's beaten every other Go algorithm in every game they've played. It also beat the European champion Fan Hui *5-0*, which is totally unprecedented. Previous algorithms could only beat strong amateur players, and were totally outclassed by top players."], [1529, "2016-02-03T19:23:31Z", 0.55, "An excerpt from the Scientific American article in the IFP background, that leapt out at me....."], [1646, "2016-02-03T18:48:48Z", 0.4, "I suggest we have an virtual game watching party for gjopen forecasters the day of the first game. Anyone care to organize it ?"], [17875, "2016-02-03T17:49:17Z", 0.76, "I'm starting around 75% as an anchor. "], [1500, "2016-02-03T17:29:10Z", 0.5, "I don't think Google would go for the match if they didn't believe they had at least a chance of winning, and they are no doubt working furiously at training and improving AlphaGo, so even though it seems unlikely that AlphaGo was ready for Lee Sedol back in October, it may be by March.  So I'm calling it a coin toss at this point."], [18920, "2016-02-03T11:12:25Z", 0.05, "I'm a go player first, and interested in AI second. As a go player I am beyond amazed at the level of play demonstrated by Alpha Go against Fan Hui. It's an incredible step forward from the level I've seen previously from go playing programs such as Zen or Crazy Stone. Still, consider the gap between Fan Hui and Lee Sedol. Fan Hui is quite strong by amateur standards but not so at the top professional level."], [18914, "2016-02-03T08:10:44Z", 0.5, "It seems most of the people predicting has never played go, and are just randomly guessing."], [18911, "2016-02-03T06:59:33Z", 0.01, "My rationale is pretty much straightforward. Lee is stronger than AlphaGo, and there's no way that AlphaGo can reach the level of Lee by upcoming March. AlphaGo needs something more to beat Lee. Something that no artificial intelligence ever accomplished -Creativity. I admit that by March, there is a good chance that AlphaGo is good at reading probably better than professionals, however it cannot go through the cognitive processes that pros do. Just like it's extremely difficult for a robot to do a simple task that a 6 year old can easily do, artificial intelligence cannot beat Lee yet unless it literally \"solves\" 19x19 go game."], [18888, "2016-02-03T04:29:27Z", 0.91, "Lee SeDol has won 68.28% of his matches as recorded on gobase.org: http://gobase.org/information/players/?pp=Lee+SeDol"], [176, "2016-02-03T03:46:16Z", 0.1, "Swayed by Einstein"], [60, "2016-02-03T03:08:11Z", 0.08, "Coming in for 8%."], [12214, "2016-02-03T02:11:28Z", 0.9, "The game (go) is bounded, no reason why a computer cannot beat a human.  Agree with another poster that the media is playing this up.  The added complexity (within bounds) would favor computer over human."], [17023, "2016-02-03T01:31:57Z", 0.86, "The main argument in favor of AlphaGo is the way it learns. It started out being fed 30 million moves from the best players and then played itself thousands of times to develop pattern recognition and strategies.  The machine then uses statistics to identify the best moves instead of trying to go through each possible move.  This gives the program an absurd amount of 'experience' to build knowledge.  Additionally, this program beat the best player in Europe 5-0 so we know it knows what it's doing and can easily beat the best.  "], [14375, "2016-02-03T00:34:17Z", 0.85, "The difficulty of computer Go is being built up and overstated, largely by tech media in search of a \"next big thing\" along the lines of Deep Blue or Watson. Expect a lot of hype around this in the coming months, but a predictable conclusion. Why would Google put it's reputation on the line for something like this if it wasn't really sure that it was going to win? The same question could have been asked about Watson or Deep Blue in their competitions. Google has no external deadline pressure to do this publicity stunt, meaning that they were able to wait until they were near certain of victory. Sedol probably doesn't mind that the odds are stacked against him because the match will raise his public profile either way."], [176, "2016-02-02T23:57:42Z", 0.15, "Playing the middle for now. I may yet regret this question. "], [241, "2016-02-02T23:52:17Z", 0.1, "There's no comparison between the World Champion (9-dan pro) and the European Champion (2-dan pro). That would be like comparing World Chess Champion Magnus Carlsen to an ordinary International Master. The Europeans have a long way to go before they play Go as well as the Koreans, Chinese, and Japanese. Maybe AlphaGo could, in this analogy, be compared to a weak Grandmaster but I am not certain of this. Fan Hui didn't seem to be taking the match seriously."], [14253, "2016-02-02T23:22:25Z", 0.95, "After beating the European champ it may now play millions/billions of more games before the big event. I think that, for a variety of reasons, a somewhat unjustified mystique has been built up around the game of Go. My guess is that if as much effort had been put into mastering Go over the years as was put into mastering chess this would have been solved already. Also, the remaing month of time left to improve its skills would be equivalent to many years of progress back in the 1990s. I say it destroys this carbon based ape!"], [17875, "2016-02-02T22:16:28Z", 0.76, "I'll raise a % because I don't think these are the relevant factors and I think this community may be underestimating AlphaGo. Maybe an edit or two would help get to them.  AlphaGo won 5-0 so it's significantly higher and the difference between European champ and World champ doesn't mean much because of that.  CPU isn't the limiting factor. AlphaGo doesn't follow human strategies ALL the time and in fact makes decisions that against \"normal\" play but are discovered to be great unexpected moves when analyzed ex-post (not creativity but simply unexpected as it uses pattern recognition).  Go is not like chess.  AlphaGo wins against other computer components 99% of the time and these vary but are generally considered so-so (even Facebook's version) as stated in the Nature article and other scholarly articles."], [2, "2016-02-02T21:34:53Z", 0.25, "Thinking through this, even the relevant factors are unknown. So going to take a whack at relevant factors:"], [17875, "2016-02-02T20:12:01Z", 0.75, "I'm currently writing a paper on this for graduate school so my bias is pretty large in favor at the moment.  I would say it is \"very possible\" and that is a lot considering how difficult this challenge is. Funny @ISherman put very possible at 40% and I think it's 50/50 with an edge to Google given the analysis of the game they played last year beating the European champion 5-0.  I actually frame it in the obverse as Sedol only has had a year to prepare/learn.  I think Lee will have to take his game to a new level if he is going to win."], [2, "2016-02-02T20:00:02Z", 0.25, "Going down a bit on @Dima-K's comment.  It took computers a while in chess to climb the grandmaster hierarchy, and I'm sure there's an equivalent one in Go."], [13341, "2016-02-02T19:43:50Z", 0.4, "Very possibly- but it is still anyone's game.  I expect it to be a very tight margin (2 - 3).  I don't know that it will be learning much over five games, most of the time neural networks take thousands or millions of games for training.  I suspect that Sedol will be learning, too, and at a much faster rate- and he'll pull victory from the jaws of defeat."], [5001, "2016-02-02T19:39:39Z", 0.05, "No contest. Computer's estimated rating is too low in comparison. DeepBlue was beating grandmasters a decade before Kasparov. The time for this fake AI will come, just not this quickly. "], [823, "2016-02-02T18:28:52Z", 0.8, "Since this match is 5 games I think AlphaGo has a good chance to win since it probably stands to \"learn\" from playing the champ."], [2, "2016-02-02T18:26:20Z", 0.45, "@dada it made it as an official question!"], [14327, "2016-02-02T18:20:10Z", 0.75, "\"The really significant thing about AlphaGo is that it (and its creators) cannot explain its moves. And yet it plays a very difficult game expertly. So it\u00e2\u20ac\u2122s displaying a capability eerily similar to what we call intuition\"\nhttp://www.theguardian.com/commentisfree/2016/jan/31/google-alphago-deepmind-artificial-intelligence-intuititive"], [4651, "2016-02-02T18:17:02Z", 0.78, "Google wouldn't schedule the match unless they were pretty sure they would win."]]}